---
editor_options: 
  chunk_output_type: console
---
```{r setup13, include=FALSE}
rm(list=ls())


source("intro.R")

```

# Stima Intervallare


## Obiettivo

Oltre alla stima di un punto specifico $\hat\theta$ dello spazio dei parametri potremmo essere interessati a trovare _regioni più verosimili_.

L'obiettivo è di stimare un intervallo nel quale pensiamo _verosimilmente_ si collochi il vero $\theta$ alla luce dei dati.

Nel gergo dei sondaggisti viene chiamata forbice.

La teoria della verosimiglianza offre tutti gli strumenti per la derivazione coerente di intervalli per una classe molto ampia di modelli di probabilità. La trattazione sistematica attraverso la verosimiglianza esula dagli scopi di questo corso.

In termini più generali per stima intervallare si intende l'indicazione di un intorno di \( \hat\theta \), costruito in modo tale da contenere il valore del parametro incognito con un certo **grado di fiducia** o **livello di affidabilità** associato al metodo di costruzione.

## Il Contesto Probabilistico

```{r 13-stima-intervallare-2} 
n <- 5
mu <- 2.5
s2 <- 1.5^2
s  <- sqrt(s2)
se <- sqrt(s2/n)
mumax <- 5
za2 <- round(qnorm(.975),2)

```

Supponiamo un caso molto speciale, vogliamo stimaare la media di una normale nell'ipotesi di conoscere la sua varianza. Siano $X_1,...X_`r n`$, $n=`r n`$ VC IID, $X_i\sim N(\mu,\sigma^2=`r s2`)$, come $\mu$ incognita.

Dalle proprietà della normale
\[\frac 1 n \sum_{i=1}^n X_i=\bar X=\hat\mu\sim N\left(\mu,\frac{\sigma^2}{n}\right), \qquad\text{ovvero }\hat \mu\sim N\left(\mu,SE^2(\hat \mu)\right) \]

Se per esempio $\mu$ fosse $\mu=`r mu`$, avremmo
\begin{eqnarray*}
\hat \mu &\sim& N\left(`r mu`,\frac{`r s2`}{`r n`}\right)\\
       &\sim& N\left(`r mu`,\left(\frac{`r s`}{\sqrt{`r n`}}\right)^2\right)\\
       &\sim& N\left(`r mu`,`r se`^2\right)
\end{eqnarray*}

La densità di probabilità di $\hat \mu$.

```{r 13-stima-intervallare-3}
par(mfrow=c(1,1),cex=cex)
curve(dnorm(x,mu,se),mu-4*se,mu+4*se,axes=F,xlab=expression(hat(mu)),ylab=expression(f(hat(mu),mu,sigma^2/n)) )
axis(1,round(mu+se*(-4:4),3) )
axis(2)
```

### Un intervallo per $\hat \mu$

Domanda: qual è quel valore $x^*>0$ tale che
\[P(\mu-x^*<\hat \mu<\mu+x^*)=0.95~~?\]

```{r 13-stima-intervallare-4}
q1 <- qnorm(.025,mu,se)
q2 <- qnorm(.975,mu,se)
curve(dnorm(x,mu,se),mu-4*se,mu+4*se,axes=F,xlab=expression(hat(mu)),ylab=expression(f(hat(mu),mu,sigma^2/n)) )
axis(1,at = c(mu-4*se,q1,mu,q2,mu+4*se), labels = c(mu-4*se,expression(mu-x^{'*'}),expression(mu),expression(mu+x^{'*'}),mu+4*se))
axis(2)

segments(c(q1,q2),c(0,0),c(q1,q2),dnorm(c(q1,q2),mu,se),lty=2)
text(mu,.1,'0.95')
text(mu-3*se ,.05,'0.025')
text(mu+3*se ,.05,'0.025')
```

qual è quel numero $x^*$ tale che
\[P(\hat \mu>\mu+x^*)=0.025,\qquad P(\hat \mu < \mu - x^*)=0.025 ~~?\]

Trasferiamo il problema sulla normale standard

Se $Z\sim N(0,1)$

Qual è quel numero $z^*$ tale che
\[P(Z>z^*)=0.025 ~~?\]

Dall'ultima riga delle tavole osserviamo che $z^*=`r za2`$, infatti
\[P(Z>`r za2`)=1- \Phi(`r za2`)=1-0.975=0.025 \]

E dunque
\[P(-19.6<Z<+`r za2`)=0.95\]

Ci serviamo delle tavole della Z per $\hat \mu$, ricordiamo che  $\hat \mu\sim N(\mu,SE^2(\hat \mu))$, allora
\[Z=\frac{\hat \mu-\mu}{SE(\hat \mu)}\sim N(0,1)\]

e quindi
\begin{eqnarray*}
  P(-`r za2`<Z<+`r za2`) &=& 0.95 \\
  P\left(-`r za2`<\frac{\hat \mu -\mu}{SE(\hat \mu)}< +`r za2`\right) &=& 0.95 \\
  P\left(-`r za2`~SE(\hat \mu)<\hat \mu -\mu< +`r za2`~SE(\hat \mu)\right) &=& 0.95 \\  
  P\left(\mu-`r za2`~SE(\hat \mu)<\mu+\hat \mu -\mu< \mu+`r za2`~SE(\hat \mu)\right) &=& 0.95 \\    
  P(\mu-`r za2`~SE(\hat \mu)<\hat \mu<\mu+`r za2`~SE(\hat \mu)) &=& 0.95
\end{eqnarray*}

Se per esempio $\mu$ fosse $\mu=`r mu`$, avremmo
\begin{eqnarray*}
  P\left(`r mu`-`r za2`~\frac{`r s`}{\sqrt{`r n`}}<\hat \mu < `r mu`+`r za2`~\frac{`r s`}{\sqrt{`r n`}}\right) &=& 0.95 \\
  P\left(`r mu`-`r za2`\times`r se`<\hat \mu < `r mu`+`r za2`\times`r se`\right) &=& 0.95 \\
  P(`r mu-za2*se` < \hat \mu < `r mu+za2*se`) &=& 0.95 
\end{eqnarray*}

```{r 13-stima-intervallare-5}
mu <- 1.2
```
Se invece $\mu= `r mu`$ allora
\begin{eqnarray*}
  P(\mu-`r za2`~SE(\hat \mu)<\hat \mu<\mu+`r za2`~SE(\hat \mu)) &=& 0.95\\
  P\left(\mu-`r za2`~\frac{\sigma}{\sqrt n}<\hat \mu < \mu+`r za2`~\frac{\sigma}{\sqrt n}\right) &=& 0.95 \\
  P\left(`r mu`-`r za2`~\frac{`r s`}{\sqrt{`r n`}}<\hat \mu < `r mu`+`r za2`~\frac{`r s`}{\sqrt{`r n`}}\right) &=& 0.95 \\
  P\left(`r mu`-`r za2`\times`r se`<\hat \mu < `r mu`+`r za2`\times`r se`\right) &=& 0.95 \\
  P(`r mu-za2*se` < \hat \mu < `r mu+za2*se`) &=& 0.95 
\end{eqnarray*}


```{r 13-stima-intervallare-6}
mu <- 3.4
```
Se $\mu= `r mu`$ allora
\begin{eqnarray*}
  P\left(`r mu`-`r za2`~\frac{`r s`}{\sqrt{`r n`}}<\hat \mu < `r mu`+`r za2`~\frac{`r s`}{\sqrt{`r n`}}\right) &=& 0.95 \\
  P\left(`r mu`-`r za2`\times`r se`<\hat \mu < `r mu`+`r za2`\times`r se`\right) &=& 0.95 \\
  P(`r mu-za2*se` < \hat \mu < `r mu+za2*se`) &=& 0.95 
\end{eqnarray*}


```{r 13-stima-intervallare-7}
mu <- 0.6
fig.def(4)
```
Se  $\mu= `r mu`$ allora
\begin{eqnarray*}
  P\left(`r mu`-`r za2`\times`r se`<\hat \mu < `r mu`+`r za2`\times`r se`\right) &=& 0.95 \\
  P(`r mu-za2*se` < \hat \mu < `r mu+za2*se`) &=& 095 
\end{eqnarray*}


Rimangono fissi $n$ e $\sigma^2$ , cambiamo $\mu$

```{r 13-stima-intervallare-8}
fig.def(4)
```


```{r 13-stima-intervallare-9}
op <- par(mfrow=c(2,2),cex=cex,mar=c(.15,.15,.15,.15))
mug <- seq(-1,mumax,length.out = 4)
xbar <- mug
plot(mug,xbar,axes = F,asp = 1,xlab = "", ylab = "",type='l')

arrows(-1,0,mumax,0,length = .1)
arrows(0,-1,0,mumax,length = .1)
text(mumax-.5,-.2,expression(mu))
text(-.2,mumax-.5,expression(hat(mu)))

lines(mug,xbar+za2*se,lty=3)
lines(mug,xbar-za2*se,lty=3)

mui <- 2.5
segments(mui,-mumax,mui,mumax)
segments(mui,mui-za2*se,mui,mui+za2*se,lwd=2,col=ared)
text(mui+.2,-.2,mui)
segments(mui,mui-za2*se,0,mui-za2*se,lty=2)
segments(mui,mui+za2*se,0,mui+za2*se,lty=2)
segments(mui,mui,0,mui,lty=2)
text(-.3,mui-za2*se,round(mui-za2*se,3))
text(-.3,mui+za2*se,round(mui+za2*se,3))
text(-.3,mui,mui)

mug <- seq(-1,mumax,length.out = 4)
xbar <- mug
plot(mug,xbar,axes = F,asp = 1,xlab = "", ylab = "",type='l')

arrows(-1,0,mumax,0,length = .1)
arrows(0,-1,0,mumax,length = .1)
text(mumax-.5,-.2,expression(mu))
text(-.2,mumax-.5,expression(hat(mu)))

lines(mug,xbar+za2*se,lty=3)
lines(mug,xbar-za2*se,lty=3)

mui <- 1.2
segments(mui,-mumax,mui,mumax)
segments(mui,mui-za2*se,mui,mui+za2*se,lwd=2,col=ared)
text(mui+.2,-.2,mui)
segments(mui,mui-za2*se,0,mui-za2*se,lty=2)
segments(mui,mui+za2*se,0,mui+za2*se,lty=2)
segments(mui,mui,0,mui,lty=2)
text(-.3,mui-za2*se,round(mui-za2*se,3))
text(-.3,mui+za2*se,round(mui+za2*se,3))
text(-.3,mui,mui)

mug <- seq(-1,mumax,length.out = 4)
xbar <- mug
plot(mug,xbar,axes = F,asp = 1,xlab = "", ylab = "",type='l')

arrows(-1,0,mumax,0,length = .1)
arrows(0,-1,0,mumax,length = .1)
text(mumax-.5,-.2,expression(mu))
text(-.2,mumax-.5,expression(hat(mu)))

lines(mug,xbar+za2*se,lty=3)
lines(mug,xbar-za2*se,lty=3)

mui <- 3.4
segments(mui,-mumax,mui,mumax)
segments(mui,mui-za2*se,mui,mui+za2*se,lwd=2,col=ared)
text(mui+.2,-.2,mui)
segments(mui,mui-za2*se,0,mui-za2*se,lty=2)
segments(mui,mui+za2*se,0,mui+za2*se,lty=2)
segments(mui,mui,0,mui,lty=2)
text(-.3,mui-za2*se,round(mui-za2*se,3))
text(-.3,mui+za2*se,round(mui+za2*se,3))
text(-.3,mui,mui)

mug <- seq(-1,mumax,length.out = 4)
xbar <- mug
plot(mug,xbar,axes = F,asp = 1,xlab = "", ylab = "",type='l')

arrows(-1,0,mumax,0,length = .1)
arrows(0,-1,0,mumax,length = .1)
text(mumax-.5,-.2,expression(mu))
text(-.2,mumax-.5,expression(hat(mu)))

lines(mug,xbar+za2*se,lty=3)
lines(mug,xbar-za2*se,lty=3)

mui <- 0.6
segments(mui,-mumax,mui,mumax)
segments(mui,mui-za2*se,mui,mui+za2*se,lwd=2,col=ared)
text(mui+.2,-.2,mui)
segments(mui,mui-za2*se,0,mui-za2*se,lty=2)
segments(mui,mui+za2*se,0,mui+za2*se,lty=2)
segments(mui,mui,0,mui,lty=2)
text(-.3,mui-za2*se,round(mui-za2*se,3))
text(-.3,mui+za2*se,round(mui+za2*se,3))
text(-.3,mui,mui)

par(op)
fig.def(4.5)
```

In sostanza

\begin{eqnarray*}
  P(\mu - 1.96 SE(\hat\mu)<\hat\mu<\mu + 1.96 SE(\hat\mu)) &=& 0.95\\
  P\left(\mu - 1.96 \frac\sigma {\sqrt n}<\hat\mu<\mu + 1.96 \frac\sigma {\sqrt n}\right) &=& 0.95
\end{eqnarray*}

Significa che la VC $\hat\mu$ si avvererà nell'intervallo $[\mu-1.96\cdot SE(\hat\mu),\mu+1.96\cdot SE(\hat\mu)]$ con probabilità 0.95.


### Invertiamo $\mu$ con $\hat\mu$

```{r 13-stima-intervallare-10}
if (!html) par(cex=.5)
mug <- seq(-1,mumax,length.out = 4)
xg <- mug
plot(mug,xg,axes = F,asp = 1,xlab = "", ylab = "",type='l')

arrows(-1,0,mumax,0,length = .1)
arrows(0,-1,0,mumax,length = .1)
text(mumax+.1,+.2,expression(mu))
text(-.2,mumax-.5,expression(hat(mu)))

lines(mug,xg+za2*se,lty=3)
lines(mug,xg-za2*se,lty=3)

xbar <- 2.6
segments(-mumax,xbar,mumax,xbar)
segments(xbar-za2*se,xbar,xbar+za2*se,xbar,col=ared,lwd=2)

segments(xbar-za2*se,0,xbar-za2*se,xbar,lty=2)
segments(xbar+za2*se,0,xbar+za2*se,xbar,lty=2)
segments(xbar        ,0,xbar        ,xbar,lty=2)

text(xbar,-.2,xbar)
text(-.25,xbar+.15,xbar)

text(xbar-za2*se,-.2,round(xbar-za2*se,3))
text(xbar+za2*se,-.2,round(xbar+za2*se,3))
arrows(xbar-za2*se,.5,xbar,.5,length = .05,code=3)
arrows(xbar+za2*se,.5,xbar,.5,length = .05,code=3)
text(xbar-za2*se/2,.65,paste(za2,"x",round(se,3)))
text(xbar+za2*se/2,.65,paste(za2,"x",round(se,3)))
```



Algebricamente, osserviamo


\begin{eqnarray*}
  P\left(\mu - 1.96 \frac\sigma {\sqrt n}<\hat\mu<\mu + 1.96 \frac\sigma {\sqrt n}\right) &=& 0.95\\
  \text{sottraggo $\hat \mu$ e $\mu$}\\
  P\left(\mu - `r za2`~\frac\sigma{\sqrt n}-\mu-\hat \mu< \mu-\mu-\hat \mu<-\hat \mu+`r za2`~\frac\sigma{\sqrt n}-\mu-\hat \mu\right) &=& 0.95 \\
  P\left(-\hat \mu- `r za2`~\frac\sigma{\sqrt n}<-\mu<-\hat \mu+`r za2`~\frac\sigma{\sqrt n}\right) &=& 0.95\\
  \left(+\hat \mu+ `r za2`~\frac\sigma{\sqrt n}>+\mu>+\hat \mu-`r za2`~\frac\sigma{\sqrt n}\right) &=& 0.95\qquad\text{cambio segno e verso}\\
  P\left(\hat \mu- `r za2`~\frac\sigma{\sqrt n}<\mu<\hat \mu+`r za2`~\frac\sigma{\sqrt n}\right) &=& 0.95\\
\end{eqnarray*}


Questa identità vale per qualunque valore di $\mu$ e quindi $\left[\hat \mu- `r za2`~\frac\sigma{\sqrt n},\hat \mu+ `r za2`~\frac\sigma{\sqrt n}\right]$ è un intervallo dagli estremi casuali che cade su $\mu$ 95 volte su 100, in media.

## Intervalli casuali

:::{.att data-latex=""}
\[  P\left(\hat \mu- `r za2`~\frac\sigma{\sqrt n}<\mu<\hat \mu+`r za2`~\frac\sigma{\sqrt n}\right) = 0.95\]
**non** è la probabilità che $\mu$ si trovi tra $\hat \mu- `r za2`~\frac\sigma{\sqrt n}$ e $\hat \mu+ `r za2`~\frac\sigma{\sqrt n}$,

\[  P\left(\hat \mu- `r za2`~\frac\sigma{\sqrt n}<\mu<\hat \mu+`r za2`~\frac\sigma{\sqrt n}\right) = 0.95\]
è la probabilità che **l'intervallo casuale** $\left[\hat \mu- `r za2`~\frac\sigma{\sqrt n},\hat \mu+ `r za2`~\frac\sigma{\sqrt n}\right]$  cada su $\mu$.
:::

Se quindi $\hat \mu = `r xbar`$ l'intervallo
\begin{eqnarray*}
 \left[\hat \mu- `r za2`~\frac\sigma{\sqrt n},\hat \mu+ `r za2`~\frac\sigma{\sqrt n}\right] &=& 
\left[`r xbar`- `r za2`~\frac{`r s`}{\sqrt `r n`},\hat \mu+ `r za2`~\frac{`r s`}{\sqrt `r n`}\right]\\
 &=& \left[`r xbar- za2*se`,`r xbar+ za2*se`\right]
\end{eqnarray*}

 L'intervallo $\left[`r xbar- za2*se`,`r xbar+ za2*se`\right]$ è una realizzazione dell'intervallo casuale $\left[\hat \mu- `r za2`~\frac\sigma{\sqrt n},\hat \mu+ `r za2`~\frac\sigma{\sqrt n}\right]$.



## Intervallo di confidenza per $\mu$ al 95%, $n=5$ e $\sigma^2=2.25$.

Se $\hat \mu = `r xbar`$ l'intervallo
\begin{eqnarray*}
 \left[\hat \mu- `r za2`~\frac\sigma{\sqrt n},\hat \mu+ `r za2`~\frac\sigma{\sqrt n}\right] &=& 
\left[`r xbar`- `r za2`~\frac{`r s`}{\sqrt `r n`},\hat \mu+ `r za2`~\frac{`r s`}{\sqrt `r n`}\right]\\
 &=& \left[`r xbar- za2*se`,`r xbar+ za2*se`\right]\\
\end{eqnarray*}
è chiamato *intervallo di confidenza* per $\mu$ al 95%.

:::{.nota data-latex=""}
Infelice traduzione di _Confidence Interval_,

  - _to be confident that the real parameter is in $\left[`r xbar- za2*se`,`r xbar+ za2*se`\right]$, with a confidence level of 95%_.
  - _Siamo fiduciosi che il vero parametro si trovi in $\left[`r xbar- za2*se`,`r xbar+ za2*se`\right]$, con un livello di fiducia del 95%_
:::

L'intervallo è costruito con una metodologia che 95 volte su 100 produce intervalli che coprono il vero $\mu$.
Il long run:

```{r 13-stima-intervallare-11}
fig.def(4)
```

```{r 13-stima-intervallare-12}
par(cex=.45)
mu <- 2
  plot(mug,xg,axes = F,asp = 1,xlab = "", ylab = "",type='l')
i <- 1
intc <- function(xbar){
  ex <- substitute(expression(mu[obs]^(i)),list(i=i))
  mug <- seq(-1,mumax,length.out = 4)
  xg <- mug

  arrows(-1,0,mumax,0,length = .1)
  arrows(0,-1,0,mumax,length = .1)
  text(mumax+.1,+.2,expression(mu))
  text(-.2,mumax-.5,expression(hat(mu)))
  
  lines(mug,xg+za2*se,lty=3)
  lines(mug,xg-za2*se,lty=3)
  
  points(0,xbar,pch=4,cex=.8,col=4)
  text(-.5,xbar,eval(ex))
  
  segments(0,mu-za2*se,mu,col='grey',lty=3)
  segments(0,mu+za2*se,mu,col='grey',lty=3)
  
  segments(mu,-mumax,mu,mumax,col='grey30')
  segments(mu,mu-za2*se,mu,mu+za2*se,lwd=1,col=ared)
  segments(0,mu-za2*se,0,mu+za2*se,lwd=1,col=ared)
  text(mu+.4,-.2,expression(mu[vera]),col=ared)
  points(mu,0,pch=16,col=ared,cex=cex)
  segments(xbar-za2*se,xbar,xbar+za2*se,xbar)
  segments(xbar-za2*se,0,xbar-za2*se,xbar,lty=2)
  segments(xbar+za2*se,0,xbar+za2*se,xbar,lty=2)
  segments(xbar        ,0,xbar        ,xbar,lty=2)
  
  text(xbar+.4,.2,eval(ex))
}
set.seed(1)
mu_rnd <- rnorm(5,mu,1.5/sqrt(5))
for (i in 1:5){intc(mu_rnd[i]); i <- i+1}

intc(3.5); i <- i+1
```


## Stimatori e intervalli di confidenza

Se $\theta$ è il parametro da stimare uno stimatore puntuale $h$ è una VC
\[\hat\theta(X_1,...,X_n)=\hat\theta\]

Siano $L_1(X_1,...,X_n)=L_1$ e $L_2(X_1,...,X_n)=L_2$ due statistiche tali che 
  $L_1\leq L_2$ per ogni campione $X_1,...,X_n$.
L'intervallo
$$[L_1,L_2]$$
è un *intervallo casuale*.

:::{.info data-latex=""}
:::{.definition}
Un  __intervallo di confidenza__ per $\theta$ al livello $(1-\alpha)\times 100\%$ è costruito su quella coppia di statistiche $L_1$ e $L_2$ tali che
\[P(L_1<\theta<L_2)=1-\alpha\]
:::
:::

Un _intervallo di confidenza_ per $\theta$ al livello $(1-\alpha)\times 100\%$ è l'intervallo $[L_1,L_2]$ calcolato sui dati del campione.

## Massima Verosimiglianza e intervalli di confidenza

Se $\hat\theta$ è lo stimatore di massima verosimiglianza per $\theta$, se $n$ è sufficientemente alto
\[\hat\theta\operatorname*{\sim}_a N(\theta,\widehat{SE^2(\hat\theta)}\equiv I^{-1}(\theta))\]


L'_intervallo di confidenza_ per $\theta$ al livello $(1-\alpha)\times 100\%$ è ricavato da: 
\[P(\hat\theta-z_{\alpha/2}\widehat{SE(\hat\theta)}<\theta<\hat\theta+z_{\alpha/2}\widehat{SE(\hat\theta)})=1-\alpha\]

Un  _intervallo di confidenza_ per $\theta$ al livello $(1-\alpha)\times 100\%$ è l'intervallo $[\hat\theta-z_{\alpha/2}\widehat{SE(\hat\theta)},\hat\theta+z_{\alpha/2}\widehat{SE(\hat\theta)}]$ calcolato sui dati del campione.


## Intervalli di Confidenza per $\mu$ al livello $(1-\alpha)\times 100$, $\sigma^2$ nota
```{r 13-stima-intervallare-13}
za2 <- round(qnorm(.975),4)
```
Sia $0<\alpha<1$, osserviamo che
\begin{eqnarray*}
  P(-z_{\alpha/2}<Z<+z_{\alpha/2}) &=& 1-\alpha \\
  P\left(-z_{\alpha/2}<\frac{\hat \mu -\mu}{SE(\hat \mu)}< +z_{\alpha/2}\right) &=& 1-\alpha \\
  P\left(\hat \mu- z_{\alpha/2}~\frac\sigma{\sqrt n}<\mu<\hat \mu+z_{\alpha/2}~\frac\sigma{\sqrt n}\right) &=& 1-\alpha
\end{eqnarray*}

:::{.info data-latex=""}
:::{.definition name="Intervallo di Confidenza per $\mu$ ($\sigma^2$ nota)"}
Si definisce L'IdC al livello $(1-\alpha)\times100\%$ per $\mu$ con $\sigma^2$ nota, l'intervallo
\[IdC:~~\left[\hat \mu- z_{\alpha/2}~\frac\sigma{\sqrt n},\hat \mu+ z_{\alpha/2}~\frac\sigma{\sqrt n}\right]\]
:::
:::

Dove $z_{\alpha/2}$ è quel valore tale che $P(Z>z_{\alpha/2})=\alpha/2$

\[  P\left(\hat \mu- z_{\alpha/2}~\frac\sigma{\sqrt n}<\mu<\hat \mu+z_{\alpha/2}~\frac\sigma{\sqrt n}\right) = 1-\alpha\]
è la probabilità che **l'intervallo casuale**
$\left[\hat \mu- z_{\alpha/2}~\frac\sigma{\sqrt n},\hat \mu+ z_{\alpha/2}~\frac\sigma{\sqrt n}\right]$
cada su $\mu$.

Il valore $0<\alpha<1$, può essere qualunque ma solitamente si usa

  - $\alpha=0.05$: intervalli al $(1-0.05)\times 100\%=0.95\times 100\%=95\%$
  - $\alpha=0.01$: intervalli al $(1-0.01)\times 100\%=0.99\times 100\%=99\%$
  - Gli intervalli per $\alpha=0.1$ e $\alpha=0.001$, intervalli al $90\%$ e al $99.9\%$ meno usati.


dalle tavole abbiamo

| $\alpha$        | $\alpha/2$            | $z_{\alpha/2}$                    |                       |           |
|:----------------|:----------------------|:----------------------------------|:----------------------|-----------|
|  $\alpha=0.1$   | con $\alpha/2=0.05$   | e quindi $z_{\alpha/2}=z_{0.05}$  | $=`r qnorm(1-.05)`$   | Raro      |
|  $\alpha=0.05$  | con $\alpha/2=0.025$  | e quindi $z_{\alpha/2}=z_{0.025}$ | $=`r qnorm(1-.025)`$  | Freq.     |
|  $\alpha=0.01$  | con $\alpha/2=0.005$  | e quindi $z_{\alpha/2}=z_{0.005}$ | $=`r qnorm(1-.005)`$  | Freq.     |
|  $\alpha=0.001$ | con $\alpha/2=0.0005$ | e quindi $z_{\alpha/2}=z_{0.005}$ | $=`r qnorm(1-.0005)`$ | Raro      |

```{r 13-stima-intervallare-14}
za2 <- qnorm(.995)
```


:::{.example}
Intervallo al 99\%, $\hat \mu=2.6$, $n=5$, $\sigma^2=`r s2`$.
L'intervallo al 99% implica un $\alpha=0.01$, infatti
\[1-\alpha=0.99\]

E dunque
\[\alpha/2=0.005\]

Dalle tavole
\[z_{\alpha/2}=z_{0.005}=`r qnorm(.995)`\]

Se quindi $\hat \mu = `r xbar`$ l'intervallo
\begin{eqnarray*}
 \left[\hat \mu- `r za2`~\frac\sigma{\sqrt n},\hat \mu+ `r za2`~\frac\sigma{\sqrt n}\right] &=&
\left[`r xbar`- `r za2`~\frac{`r s`}{\sqrt `r n`},`r xbar`+ `r za2`~\frac{`r s`}{\sqrt `r n`}\right]\\
 &=& \left[`r xbar- za2*se`,`r xbar+ za2*se`\right]
\end{eqnarray*}

È l'intervallo di confidenza per $\mu$ al $99\%$
:::

```{r 13-stima-intervallare-15}
za2 <- qnorm(.95)
fig.def()
```

:::{.example }
Intervallo al $99\%$, $\hat \mu=2.6$, $n=5$, $\sigma^2=`r s2`$. L'intervallo al 90% implica un $\alpha=0.1$, infatti
\[1-\alpha=0.90\]

E dunque
\[\alpha/2=0.05\]

Dalle tavole
\[z_{\alpha/2}=z_{0.05}=`r qnorm(.95)`\]

Se quindi $\hat \mu = `r xbar`$ l'intervallo
\begin{eqnarray*}
 \left[\hat \mu- `r za2`~\frac\sigma{\sqrt n},\hat \mu+ `r za2`~\frac\sigma{\sqrt n}\right] &=&
\left[`r xbar`- `r za2`~\frac{`r s`}{\sqrt `r n`},`r xbar`+ `r za2`~\frac{`r s`}{\sqrt `r n`}\right]\\
 &=& \left[`r xbar- za2*se`,`r xbar+ za2*se`\right]
\end{eqnarray*}

È l'intervallo di confidenza per $\mu$ al $90\%$.
:::

Osserviamo graficamente gli intervalli di confidenza per $\mu$ con $\hat \mu=`r xbar`$, $n=`r n`$ e $\sigma^2=`r s2`$, al 90%, 95%, 99% e 99.9%.



```{r 13-stima-intervallare-1,results='asis'}
plot(c(xbar-4.5*se,xbar+4.5*se),c(-.4,1),axes=F,xlab='',ylab="",type='n')
arrows(xbar-4.5*se,0,xbar+4.5*se,0,length = .1)
points(xbar,0,pch='|')
text(xbar+.15,-.05,expression(hat(mu)))
alp <- c(.1,.05,.01,.001)
IdC <- function(a) c(xbar+c(-1,1)*qnorm(1-a/2)*se,2*qnorm(1-a/2)*se)
for (i in 1:length(alp)){
segments(IdC(alp[i])[1],i/7,IdC(alp[i])[2],i/7,col=i+1)
segments(IdC(alp[i])[1:2],0,IdC(alp[i])[1:2],i/7,lty = 2,col= i+1)
text(xbar,i/7,pos = 1,paste("intervallo al",(1-alp[i])*100,"%"),cex=.5)
}

tb <- data.frame(sapply(alp, IdC))
row.names(tb) <- c("$\\hat \\mu - z_{\\alpha/2}SE(\\hat \\mu)$","$\\hat \\mu + z_{\\alpha/2}SE(\\hat \\mu)$","Ampiezza")
colnames(tb) <- paste("$\\alpha=",alp,"$",sep='')

kable(tb,row.names = T,booktabs = T, escape = F,linesep = "", digits = 4)
```


:::{.example}

```{r 13-stima-intervallare-16}
xbar <- 19
sbar <- 1.979
s    <- 1.5
n    <- 6
```
Un venditore di bustine di tè assicura che ogni bustina ha un
peso medio pari a 20g con una SD pari a 1.5g.
L'acquirente esegue 6 misure di controllo e ottiene i seguenti
risultati: 19; 20; 20.5; 21; 18.5; 15.
La media di questi numeri è $\hat\mu = 19$ e $\widehat{\sigma}=1.979$.
Determinare un IdC al livello di $(1-\alpha)=0.99$ per $\mu$.

\begin{eqnarray*}
& & \left[\hat\mu -z_{\alpha/2} \frac{\sigma} {\sqrt{n}};
          \hat\mu +z_{\alpha/2} \frac{\sigma} {\sqrt{n}} \right] \\
&=& \left[ 19 -2.576 \frac{1.5} {\sqrt{6}}; 19 +2.576 \frac{1.5} {\sqrt{6}} \right] \\
&=& \left[ 19 - 1.5775; 19 + 1.5775 \right]        \\
&=& \left[ 17.4225;\quad 20.5775 \right]
\end{eqnarray*}

Notare la modalità di indicare la SD della $\cal{P}$ e dei dati.
Vi sono due informazioni su $\sigma$ e bisogna scegliere quella giusta.
:::


## Intervalli di Confidenza per $\mu$ al livello $(1-\alpha)\times 100$, $\sigma^2$ incognita

Se $\sigma^2$ è incognito va stimato dai dati

Consideriamo lo stimatore $S^2$ di $\sigma^2$
\[S^2=\frac {1}{n-1}\sum_{i=1}^n (X_i-\hat \mu)^2=\frac {n}{n-1}\frac 1 n\sum_{i=1}^n (X_i-\hat \mu)^2=\frac n {n-1}\hat\sigma^2\]

Ricordiamo che
\[\widehat{SE(\hat\mu)}=\sqrt{\frac {S^2}n}=\frac S {\sqrt n}\]

Ricordiamo infine che
\[T=\frac{\hat \mu-\mu}{\widehat{SE(\hat\mu)}}\sim t_{n-1}\]

Ovvero
\[T=\frac{\hat \mu-\mu}{S/\sqrt n}\sim t_{n-1}\]



### $\sigma$ nota e $\sigma$ incognita

Se $\sigma$ è nota
\[Z=\frac{\hat \mu-\mu}{\sigma/\sqrt n}\sim N(0,1)\]

Se $\sigma$ è incognita
\[T=\frac{\hat \mu-\mu}{S/\sqrt n}\sim t_{n-1}\]


Sia $0<\alpha<1$, osserviamo che
\begin{eqnarray*}
  P(-t_{n-1;\alpha/2}<T<+t_{n-1;\alpha/2}) &=& 1-\alpha \\
  P\left(-t_{n-1;\alpha/2}<\frac{\hat \mu -\mu}{\widehat{SE(\hat \mu)}}< +t_{n-1;\alpha/2}\right) &=& 1-\alpha \\
  P\left(\hat \mu- t_{n-1;\alpha/2}~\frac S{\sqrt n}<\mu<\hat \mu+t_{n-1;\alpha/2}~\frac S{\sqrt n}\right) &=& 1-\alpha
\end{eqnarray*}

Dove $t_{n-1;\alpha/2}$ è quel valore tale che $P(T>t_{n-1;\alpha/2})=\alpha/2,\qquad T\sim t_{n-1}$

:::{.info data-latex=""}
:::{.definition name="Intervallo di Confidenza per $\mu$ ($\sigma^2$ incognita)"}
Si definisce L'IdC al livello $(1-\alpha)\times100\%$ per $\mu$ con $\sigma^2$ incognita, l'intervallo
\[IdC:~~\left[\hat \mu- t_{n-1;\alpha/2}~\frac S{\sqrt n},\hat \mu+ t_{n-1;\alpha/2}~\frac S{\sqrt n}\right]\]
:::
:::

\[  P\left(\hat \mu- t_{n-1;\alpha/2}~\frac S{\sqrt n}<\mu<\hat \mu+t_{n-1;\alpha/2}~\frac S{\sqrt n}\right) = 1-\alpha\]
è la probabilità che **l'intervallo casuale** $\left[\hat \mu- t_{n-1;\alpha/2}~\frac S{\sqrt n},\hat \mu+ t_{n-1;\alpha/2}~\frac S{\sqrt n}\right]$  cada su $\mu$.


:::{.example}
Un venditore di bustine di tè assicura che ogni bustina ha un
peso medio pari a 20g.
L'acquirente esegue 6 misure di controllo e ottiene i seguenti
risultati: 19; 20; 20.5; 21; 18.5; 15.
La media di questi numeri è $\hat\mu = 19$ e $\widehat{\sigma}=1.979$.
Determinare un IdC al livello di $(1-\alpha)=0.99$ per $\mu$.

\[\alpha=0.01\qquad \alpha/2=0.005,\qquad t_{6-1;0.005}=`r round(qt(1-.005,5),4)`\]


\begin{eqnarray*}
& & S = \sqrt{\frac{n} {n-1}} \widehat{\sigma}
      =  \sqrt{\frac{6} {6-1}} 1.979 = 2.1679                        \\
& & \left[\hat\mu -t_{(n-1); \alpha/2} \frac{S} {\sqrt{n}};
          \hat\mu +t_{(n-1); \alpha/2} \frac{S} {\sqrt{n}} \right] \\
&=& \left[ 19 -4.0321 \frac{2.1679} {\sqrt{6}};  19 +4.0321 \frac{2.1679} {\sqrt{6}} \right]               \\
&=& \left[ 19 - 3.5687;~ 19 + 3.5687 \right]                          \\
&=& \left[ 15.4313; 22.5687 \right]
\end{eqnarray*}

Si noti che la mancanza di informazioni sulla varianza rende più
incerto il risultato; infatti, la lunghezza dell'IdC aumenta.
:::

:::{.example}
Si sono rilevati i tempi dedicati a ciascun cliente da un impiegato
di banca in 49 casi e si è ottenuta una media $\bar{x}=3.5$ minuti
con una SD pari a 0.5 minuti.
Determinare un IdC al livello di $(1-\alpha)=0.95$ per $\mu$.

\[\alpha=0.05\qquad \alpha/2=0.025.\qquad t_{49-1;0.025}=`r round(qt(1-.025,48),4)`\]

\begin{eqnarray*}
& & s = \sqrt{\frac{n} {n-1}} \widehat{\sigma}
      =  \sqrt{\frac{49} {49-1}} 0.5 = 0.505                         \\
& & \left[\bar{X} -t_{(n-1);  \alpha/2} \frac{S} {\sqrt{n}};
          \bar{X} +t_{(n-1);  \alpha/2} \frac{S} {\sqrt{n}} \right] \\
&=& \left[ 3.5 -2.0106 \frac{0.505} {\sqrt{49}};
           3.5 +2.0106 \frac{0.505} {\sqrt{49}} \right]              \\
&=& \left[ 3.5 - 0.145; 3.5 + 0.145 \right]                          \\
&=& \left[ 3.355; 3.645 \right]
\end{eqnarray*}

Si noti che per $n>120$ si può approssimare con una normale.
:::




## IDC per la proporzione

$X_{1}, \ldots, X_{n}$ VC IID, tutte $\text{Ber}(\pi)$. Per il TLC
\[\bar{X} = \hat\pi \operatorname*{\sim}_a
    N\left( \pi;\, \frac{\pi (1-\pi)} {n} \right) \Rightarrow \hat\pi \operatorname*{\sim}_a N\left( \pi; SE^2(\hat\pi)\right)\]

E quindi
\[Z = \frac{\hat\pi - \pi} {SE(\hat\pi)} \operatorname*{\sim}_a N(0,1) \Rightarrow P\left(-z_{\alpha/2} < \frac{\hat\pi - \pi} {SE(\hat\pi)}   < z_{\alpha/2} \right) = 1-\alpha
    \]


Infine
\begin{eqnarray*}
P\left(\hat\pi -z_{\alpha/2} {SE(\hat\pi)} < \pi
          <\hat\pi +z_{\alpha/2} {SE(\hat\pi)} \right) &=& 1-\alpha \\
P\left(\hat\pi -z_{\alpha/2} \sqrt{\frac{\pi(1-\pi)}{n}} < \pi
          <\hat\pi +z_{\alpha/2} \sqrt{\frac{\pi(1-\pi)}{n}} \right) &=& 1-\alpha
\end{eqnarray*}

l'IdC DIPENDE da $\pi$ NON NOTA.
Per il TLC e $n$ sufficientemente grande si può sostituire
a $\pi$ dell'IdC la sua stima $\hat\pi$.
\[\widehat{SE(\hat\pi)}=\sqrt\frac{\hat\pi(1-\hat\pi)}{n}\]

Condizioni per l'approssimazione
\[n\, \pi \ge 5 \quad\text{e}\quad  n\, (1-\pi) \ge 5\]

e quindi l'IdC al livello $(1-\alpha)\times 100$ per $\hat\pi$ è:

:::{.info data-latex=""}
:::{.definition name="Intervallo di Confidenza per $\pi$"}
Si definisce L'IdC al livello $(1-\alpha)\times100\%$ per $\pi$ l'intervallo
\[\left[\,\hat\pi-z_{\alpha/2}\sqrt\frac{\hat\pi(1-\hat\pi)}{n};\hat\pi+z_{\alpha/2}\sqrt\frac{\hat\pi(1-\hat\pi)}{n}\,\right]\]
:::
:::



:::{.example}
Una indagine sulle intenzioni di voto degli italiani per lo schieramento $A$ ha mostrato
che 240 su 500 lo voterebbero. Determinare un IdC al livello di $(1-\alpha)=0.99$ per $\pi$.
\[\alpha=0.01,\qquad \alpha/2=0.005,\qquad z_{0.005}=`r round(qnorm(1-.005),4)`\]

\begin{eqnarray*}
& & \hat\pi = \frac{\mbox{favorevoli}} {n}
                = \frac{240} {500} = 0.48                            \\
& & \left[\hat\pi -z_{\alpha/2}
          \sqrt{\frac{\hat\pi (1-\hat\pi)} {n}};
          \hat\pi +z_{\alpha/2}
          \sqrt{\frac{\hat\pi (1-\hat\pi)} {n}} \right]     \\
&=& \left[  0.48 -2.576 \sqrt{\frac{0.48 (1-0.48)} {500}}; 0.48 +2.576 \sqrt{\frac{0.48 (1-0.48)} {500}} \right]  \\
&=& \left[ 0.48 - `r qnorm(.995)*sqrt(.48*(1-.48)/500)`; 0.48 + `r qnorm(.995)*sqrt(.48*(1-.48)/500)`\right]                     \\
&=& \left[ `r .48-qnorm(.995)*sqrt(.48*(1-.48)/500)`; `r .48+qnorm(.995)*sqrt(.48*(1-.48)/500)` \right]
\end{eqnarray*}
:::

:::{.example}
Una indagine sulle intenzioni di voto degli italiani per lo schieramento $A$ ha mostrato
che 2400 su 5000 lo voterebbero. Determinare un IdC al livello di $(1-\alpha)=0.99$ per $\pi$.

\begin{eqnarray*}
& & \hat\pi = \frac{\mbox{favorevoli}} {n}
                = \frac{2400} {5000} = 0.48                            \\
& & \left[\hat\pi -z_{\alpha/2}
          \sqrt{\frac{\hat\pi (1-\hat\pi)} {n}};
          \hat\pi +z_{\alpha/2}
          \sqrt{\frac{\hat\pi (1-\hat\pi)} {n}} \right]     \\
&=& \left[  0.48 -2.576 \sqrt{\frac{0.48 (1-0.48)} {5000}}; 0.48 +2.576 \sqrt{\frac{0.48 (1-0.48)} {5000}} \right]  \\
&=& \left[ 0.48 - `r qnorm(.995)*sqrt(.48*(1-.48)/5000)`; 0.48 + `r qnorm(.995)*sqrt(.48*(1-.48)/5000)`\right]                     \\
&=& \left[ `r .48-qnorm(.995)*sqrt(.48*(1-.48)/5000)`; `r .48+qnorm(.995)*sqrt(.48*(1-.48)/5000)` \right]
\end{eqnarray*}
:::

### IdC per $\pi$ per $\alpha$ ed $n$ fissati

`r n <- 50`Se fissiamo $\alpha$ ed $n$, per esempio $\alpha=0.05$ ed $n=`r n`$, possiamo variare $S_n\in\{0,...,n\}$ e quindi $\hat\pi\in{0/n,1/n,...,n/n}$. Per ogni valore di $\hat\pi$ calcoliamo l'IdC al livello $(1-\alpha)$ e rappresentiamo graficamente

```{r 13-stima-intervallare-17}
fig.def(3,3)
```

```{r 13-stima-intervallare-18}

op <- par(cex=.5,mar=c(5.1,5.1,.1,.1))

ap <- 0
plot(c(0,1),c(0,1),axes=F,xlab="",ylab="",type="n",asp=1,col="grey")
curve(x-1.96*sqrt(x*(1-x)/n),ap,1-ap,add=T,col="grey")
curve(x+1.96*sqrt(x*(1-x)/n),ap,1-ap,add=T,col="grey")
curve(x-1.96*sqrt(x*(1-x)/n),5/n,1-5/n,add=T,col=iblue,lwd=1.5)
curve(x+1.96*sqrt(x*(1-x)/n),5/n,1-5/n,add=T,col=iblue,lwd=1.5)


title(xlab=expression(hat(pi)),mgp=c(4,4,0))
title(ylab=expression(pi),mgp=c(4,4,0))

segments(x0 = .5,y0 = .5-1.96*sqrt(.25/n),x1 = 0,y1 = .5-1.96*sqrt(.25/n),lty=2,col=iblue)
segments(x0 = .5,y0 = .5+1.96*sqrt(.25/n),x1 = 0,y1 = .5+1.96*sqrt(.25/n),lty=2,col=iblue)

segments(x0 = .1,y0 = .1-1.96*sqrt(.09/n),x1 = 0,y1 = .1-1.96*sqrt(.09/n),lty=2,col=iblue)
segments(x0 = .1,y0 = .1+1.96*sqrt(.09/n),x1 = 0,y1 = .1+1.96*sqrt(.09/n),lty=2,col=iblue)


axis(1,(0:20)/20,las=2)
axis(2,round(c(.5-1.96*sqrt(.25/n),.5+1.96*sqrt(.25/n),.1+1.96*sqrt(.09/n),.1-1.96*sqrt(.09/n),.5,.1),4),las=2,mgp = c(100,1,0))
abline(0,1,lty=2)
abline(h=.5,lty=2,col=ared)
abline(v=.5,lty=2,col=ared)
text(.51,.01,"per pi = 0.5 si ottiene l'intervallo più ampio",pos=4)
par(op)
```

## Specchietto Finale per gli IdC

:::{.info2 data-latex=""}

- Si definisce L'IdC al livello $(1-\alpha)\times100\%$ per $\mu$ con $\sigma^2$ nota, l'intervallo
\[IdC:~~\left[\hat \mu- z_{\alpha/2}~\frac\sigma{\sqrt n},\hat \mu+ z_{\alpha/2}~\frac\sigma{\sqrt n}\right]\]
- Si definisce L'IdC al livello $(1-\alpha)\times100\%$ per $\mu$ con $\sigma^2$ incognita, l'intervallo
\[IdC:~~\left[\hat \mu- t_{n-1;\alpha/2}~\frac S{\sqrt n},\hat \mu+ t_{n-1;\alpha/2}~\frac S{\sqrt n}\right]\]
- Si definisce L'IdC al livello $(1-\alpha)\times100\%$ per $\pi$ l'intervallo
\[\left[\,\hat\pi-z_{\alpha/2}\sqrt\frac{\hat\pi(1-\hat\pi)}{n};\hat\pi+z_{\alpha/2}\sqrt\frac{\hat\pi(1-\hat\pi)}{n}\,\right]\]
:::
