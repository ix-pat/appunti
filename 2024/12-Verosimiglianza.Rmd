---
editor_options: 
  chunk_output_type: console
---
```{r setup12, include=FALSE}
rm(list=ls())


source("intro.R")

```


# Teoria della Verosimiglianza



## Il Modello Statistico

Un modello statistico è l'insieme di un modello probabilistico $X_i\sim\mathscr{L}(\theta)$
e di un piano di campionamento dalla popolazione $\mathscr{P}$. 
In queste pagine considereremo come unico piano di campionamento il campionamento casuale semplice **con** reintroduzione, ovvero assumeremo sempre le ipotesi IID. 
Per esempio sono un modello statistico:

  - Le $X_1,...,X_n$ sono IID, replicazioni di $X\sim\text{Ber}(\pi)$, $\pi\in[0,1]$ .
  - Le $X_1,...,X_n$ sono IID, replicazioni di $X\sim\text{Pois}(\lambda)$, $\lambda\in\mathbb{R}^+$.
  - Le $X_1,...,X_n$ sono IID, replicazioni di $X\sim N(\mu,\sigma^2)$, $(\mu,\sigma^2)\in\mathbb{R}\times\mathbb{R}^+$.
  - Le $X_1,...,X_n$ sono IID, replicazioni di $X\sim \mathscr{L}(\theta)$, $\theta\in\Theta$-

### Esiste lo stimatore più efficiente?

Dipende dalle informazioni che abbiamo sulla Popolazione $\mathscr{P}$
In contesti _distribution free_ e ipotesi IID, senza alcuna ulteriore conoscenza della popolazione, non esistono procedure che possano essere dimostrate _ottimali_, il ricercatore valuta da caso a caso, previa un'attenta analisi descrittiva preliminare.
In ipotesi _distribution free_ l'intera distribuzione della variabile $X$ è incognita.
Se spostiamo l'attenzione all'_inferenza da modello_ ipotizziamo di conoscere la forma della distribuzione di probabilità delle $X$ a meno dei suoi parametri.

Sotto alcune condizioni di regolarità gli stimatori più efficienti sono gli stimatori di Massima Verosimiglianza.
Lo stimatore di massima verosimiglianza parte dell'assunto che tutta l'informazione che un campione 
porge nella comprensione della popolazione risieda in una misura chiamata _Verosimiglianza_.

## La Verosimiglianza

La _Verosimiglianza_ è una misura di incertezza __non__ sul risultato di un 
esperimento casuale, ma sui meccanismi che generano una sequenza casuale.
Nella teoria della verosimiglianza si può parlare di probabilità solo per il campione,
ma non per i meccanismi che lo hanno generato. Una volta osservati i dati la conoscenza
di questi meccanismi diventa più o meno _verosimile_ agli occhi del ricercatore alla
luce dell'osservazione.

Nella teoria della verosimiglianza, dunque, si usano due termini diversi: _probabilità_ 
per indicare la misura dell'incertezza sui risultati dell'estrazione del campione e 
_verosimiglianza_ per indicare la misura di incertezza sui meccanismi che hanno prodotto il
campione.

La _teoria della verosimiglianza_ presuppone la totale ignoranza del ricercatore 
che esplora un sistema casuale di cui sta cercando di comprendere i parametri. 

Se per esempio voglio conoscere la probabilità $\pi$ di una moneta truccata di 
porgere Testa, la teoria della verosimiglianza presuppone che per me, 
prima di osservare il campione, tutti i possibili valori di $\pi$ siano 
equamente verosimili, compresi quelli più estremi.

Questa totale ignoranza non è sempre giustificata e per allargare la teoria della
verosimiglianza rimando il lettore su testi di statistica Bayesiana che sfruttano 
il teorema di Bayes per costruire una misura alternativa (più ampia) della 
verosimiglianza, basata solo sul concetto allargato di probabilità.

> Donovan, T. M., and Mickey, R. M. (2019). Bayesian Statistics for Beginners: A Step-by-Step Approach. Oxford: Oxford University Press.

La _funzione di verosimiglianza_ è la una funzione di probabilità dei dati, 
fissata sul campione osservato, in cui la variabile è il parametro. La verosimiglianza è
indicata con la lettera $L$ (_Likelihood_) e si scrive

::: {.info data-latex=""}
\[
L(\theta;\text{Dati})\propto P(\text{Dati};\theta)
\]
:::

e si legge che la _verosimiglianza_  $L$ di $\theta$ è proporzionale $\propto$ alla
probabilità di osservare i dati osservati nell'ipotesi che $\theta$ sia vera.
Il simbolo proporzionale $\propto$ significa che:
\[
L(\theta;\text{Dati})=Const.\cdot P(\text{Dati};\theta)
\]
dove $Const.$ è una constante qualunque che non dipende da $\theta$.
Il valore di $L(\theta;\text{Dati})$ per un $\theta$ fissato, non ha alcune significato 
se non è confrontato con altri valori. Infatti $L(\theta;\text{Dati})$ **non** è una
probabilità, ma se
\[
L(\theta_1;\text{Dati})> L(\theta_2;\text{Dati})
\]
Significa che l'ipotesi che sia stato $\theta=\theta_1$ il valore del parametro del 
modello che ha generato i dati è più verosimile dell'ipotesi che sia 
stato $\theta=\theta_2$.

### La Verosimiglianza attraverso un esempio

Supponiamo di avere un'urna che ha solo $N=10$ bussolotti alcuni bianchi $B$ e i rimanenti non bianchi $\overline{B}=N-B$, ma non conosciamo $B$.
Il numero di bianchi $B$ potrà essere $0, 1,...,10$.
La VC $X$ che registra l'evento bianco o nero di una estrazione è chiaramente Bernoulli $X\sim\text{Ber}(\pi)$ di parametro:
\[\pi=\frac B {10}\]
$\pi$ è la proporzione di bussolotti bianchi nell'urna.
In questo specifico esempio:
\[\pi\in\left\{\frac 0{10}=0.0,\frac{1}{10}=0.1,...,\frac 9 {10}=0.9,\frac{10}{10}=1.0\right\}\]
Lo spazio dei parametri ha dimensione 11.
Uno stimatore ha il compito di scegliere uno di questi 11 valori.

Estraiamo $n=5$ bussolotti CR (IID) e otteniamo
\[x_1=0,x_2=1,x_3=1,x_4=0,x_5=1\]

```{r 12-Verosimiglianza-2}
xs <- c(0,1,1,0,1)
```

Se conoscessi $\pi$ attraverso il calcolo delle probabilità saprei calcolare la 
probabilità della sequenza (ordinata) 0,1,1,0,1 proveniente da 5 esperimenti di 
Bernoulli IID

\begin{multline*}
P(X_1=0\cap X_2=1 \cap X_3=1 \cap X_4=0\cap X_5=1;\pi) = \\
\begin{array}{ll}
  = &P(X_1=0;\pi)P(X_2=1;\pi)P(X_3=1;\pi)P(X_4=0;\pi)P(X_5=1;\pi)\\
  = &(1-\pi)\pi\pi(1-\pi)\pi\\
  = &\pi^3(1-\pi)^{5-3}
\end{array}
\end{multline*}

La posso calcolare per ogni possibile valore di $\pi\in\{0.0,0.1,...,1.0\}$.

### Se $\pi$ fosse...

A questo punto graduare decidere i valori di $\pi$ tra più e meno _verosimili_
alla luce dei dati $\mathbf{x}=(0,1,1,0,1)$. Questo si fa sostituendo $\pi$ con
i suoi possibili valori e calcolando la _ipotetica_ probabilità.


```{r 12-Verosimiglianza-1,results='asis'}
pp <- (0:10)/10
for (i in 1:11){
  cat("Se fosse $\\pi=$",pp[i]," con quale probabilità avrei osservato la sequenza $0,1,1,0,1$? \n")
  cat("\\[ \n")
  cat(pp[i],"^3\\cdot(1-",pp[i],")^2=",pp[i]^3*(1-pp[i])^2," \\qquad\\text{l'ipotesi $\\pi=",pp[i],"$ ha verosimiglianza proporzionale a",
      pp[i]^3*(1-pp[i])^2,"}\n")
  cat("\\]\n")
}
```

Definiamo la **funzione di verosimiglianza** (Likelihood), la funzione $L$ del parametro incognito $\pi$ alla luce dei dati $X_1=0,X_2=1,X_3=1,X_4=1,X_5=1$ osservati:
\begin{multline*}
  L(\pi;X_1=0,X_2=1,X_3=1,X_4=1,X_5=1) =  \\
  \begin{array}{ll}
     = &L(\pi)\\
     = &K\cdot P(X_1=0\cap X_2=1\cap X_3=1\cap X_4=1\cap X_5=1;\pi) \qquad \text{con $K> 0$}\\
     \propto & P(X_1=0\cap X_2=1\cap X_3=1\cap X_4=1\cap X_5=1;\pi)\\
     \propto & \pi^3(1-\pi)^2
  \end{array}
\end{multline*}
La verosimiglianza gradua quanto un certo valore di $\pi$ è compatibile con i dati
osservati. Per esempio l'ipotesi $\pi=0.5$ è più verosimile dell'ipotesi $\pi=0.4$, alla luce dei dati
$x_1=0,x_2=1,x_3=1,x_4=0,x_5=1$,
\[
L(0.5)=`r .5^3*(.5)^2`>L(0.4)=`r .4^3*.6^2`
\]
Se mettiamo $\pi$ in ascissa e $L(\pi)$ in ordinata, otteniamo il grafico della verosimiglianza di $\pi$, alla luce dei dati osservati.

```{r 12-Verosimiglianza-3}
xs <- c(0,1,1,0,1)
n <- length(xs)
sn <- sum(xs)
pp <- (0:10)/10
Lp <- data.frame(pp^3*(1-pp)^2)
rnm <-paste("$\\pi=",pp,"$", sep = "")
rownames(Lp) <- rnm
names(Lp) <- "$L(\\pi)$"
fig.def()
```

```{r 12-Verosimiglianza-4}
plot(pp,Lp[,1],axes=F,xlab=expression(pi),ylab=expression(L(pi)))
segments(pp,0,pp,Lp[,1] ,lty=2)
axis(1,pp)
axis(2,las=2)
fig.def(4)
```

### La verosimiglianza non è una probabilità

Notiamo che
\[\sum_{\pi\in\{0.0,0.1,...,1.0\}}L(\pi) = `r Lp[1,1]`+`r Lp[2,1]`+...+`r Lp[11,1]`=`r sum(Lp[,1])`\neq 1\]

La possiamo moltiplicare per un numero qualunque

```{r 12-Verosimiglianza-5}
par(mfrow=c(2,2),cex=cex)
plot(pp,Lp[,1],axes=F,xlab=expression(pi),ylab=expression(L(pi)), main = expression(P(x[1],...,x[n],pi)),type="h",lwd=2,col=ared)
axis(1,pp)
axis(2,las=2)

plot(pp,10*Lp[,1],axes=F,xlab=expression(pi),ylab=expression(L(pi)), main = expression(10 %*%P(x[1],...,x[n],pi)),type="h",lwd=2,col=ared)
axis(1,pp)
axis(2,las=2)

plot(pp,(1/2)*Lp[,1],axes=F,xlab=expression(pi),ylab=expression(L(pi)), main = expression(1/ 2 %*%P(x[1],...,x[n],pi)),type="h",lwd=2,col=ared)
axis(1,pp)
axis(2,las=2)

plot(pp,(1/0.035)*Lp[,1],axes=F,xlab=expression(pi),ylab=expression(L(pi)), main = expression(1/ .035 %*%P(x[1],...,x[n],pi)),type="h",lwd=2,col=ared)
axis(1,pp)
axis(2,las=2)

par(mfrow=c(1,1),cex=cex)
```

### La stima di massima verosimiglianza

$\hat\pi_{ML}=\hat\pi$ è 
\[\hat\pi\in\{0.0,0.1,0.2,...,1.0\}: L(\hat\pi)>L(\pi),\forall\pi\neq\hat\pi\]

E quindi:
\[\hat\pi=0.6=\frac 3 5\]

Consideriamo $\ell$, il logaritmo di $L$
\[\ell(\pi)=\log L(\pi)\]


```{r 12-Verosimiglianza-6}
xs <- c(0,1,1,0,1)
n <- length(xs)
sn <- sum(xs)
pp <- (0:10)/10
rnm <-paste("$\\pi=",pp,"$", sep = "")
Lp <- data.frame(pp,pp^3*(1-pp)^2,log(pp^3*(1-pp)^2))
rownames(Lp) <- rnm
names(Lp) <- c("$\\pi=$","$L(\\pi)$","$\\ell(\\pi)$")
kable(t(Lp),booktabs=T, escape = F,linesep = "", digits = 4,col.names = NULL)

fig.def()
```

```{r 12-Verosimiglianza-7}
par(mfrow=c(1,2),cex=cex)
plot(pp,Lp[,2],axes=F,xlab=expression(pi),ylab=expression(L(pi)),main = "L",pch=16,type='b')
segments(sn/n,0,sn/n,(sn/n)^sn*(1-sn/n)^(n-sn),lty=2)
axis(1,pp)
axis(2,las=2)
Lp[is.infinite(Lp[,2]),2]<- - 100
plot(pp,Lp[,3],axes=F,xlab=expression(pi),ylab=expression(L(pi)),main = "log L",pch=16,type='b',ylim=c(-8,-3))
segments(sn/n,-9,sn/n,log((sn/n)^sn*(1-sn/n)^(n-sn)),lty=2)
axis(1,pp)
axis(2,las=2)
```


### Esempio IID da popolazione finita (parte due)

Riprendiamo l'esempio di prima: un'urna che ha solo $N=10$ bussolotti alcuni bianchi $B$ altri neri $N$, ma non conosciamo $B$ ed $N$.
Il numero di bianchi $B$ potrà essere $0, 1,...,10$ e 
$\pi$ è la proporzione di bussolotti bianchi nell'urna
\[\pi=\frac B{10}\]

Estraiamo $n=5$ bussolotti CR (IID) e otteniamo 
3 _successi_ (bussolotto bianco) e 2 _insuccessi_ (bussolotto nero).
Non conosciamo l'ordine.
  
$X\sim\text{Binom}(5,\pi)$, il mio campione è un'estrazione dalla binomiale con $n=5$.
Speculiamo su $\pi$

```{r 12-Verosimiglianza-8}
xs <- c(0,1,1,0,1)
```

Se conoscessi $\pi$ attraverso il calcolo delle probabilità saprei calcolare la probabilità $P(X)=3$, con $X\sim\text{Binom}(5,\pi)$
\[
P(X=3;\pi) =   \binom{5}{3}\pi^3(1-\pi)^{5-3} =`r choose(5,3)`\cdot \pi^3(1-\pi)^2
\]

Se fosse $\pi=0$ ($B=0$) con quale probabilità avrei osservato la sequenza $X=3$?
\[\binom{5}{3}0^3\cdot(1-0)^2=0\]
  - l'ipotesi $\pi=0$ ha **verosimiglianza** proporzionale a zero

Se fosse $\pi=0.1$ ($B=1$) con quale probabilità avrei osservato la sequenza $X=3$?
\[\binom{5}{3}0.1^3\cdot(1-0.1)^2=`r dbinom(3,5,.1) `\]
  - l'ipotesi $\pi=0.1$ ha **verosimiglianza** proporzionale a `r dbinom(3,5,.1)`

...

Definiamo la funzione di verosimiglianza (Likelihood), la funzione $L$ del parametro incognito $\pi$ alla luce dei dati $x=3$ osservati:
\begin{eqnarray*}
  L(\pi;x=3) &=& L(\pi) \\
            &\propto& P(x=3;\pi)\\
            &=& \binom{5}{3}\pi^3(1-\pi)^2\\
            &\propto& \pi^3(1-\pi)^2
\end{eqnarray*}

La tabella

```{r two-column, results='asis', echo=FALSE, out.extra=''}
xs <- c(0,1,1,0,1)
n <- length(xs)
sn <- sum(xs)
pp <- (0:10)/10
Lp <- data.frame(pp,pp^3*(1-pp)^2,log(pp^3*(1-pp)^2))
rnm <-0:10
rownames(Lp) <- rnm
cn <- rep("",times=11)
names(Lp) <- c("$\\pi=$","$L(\\pi)$","$\\log(L(\\pi))$")

kable(t(Lp),col.names = NULL ,booktabs=T, escape = F,linesep = "", digits = 4)
```

e il grafico


```{r 12-Verosimiglianza-9}
par(mfrow=c(1,2),cex=cex)
plot(pp,Lp[,2],axes=F,xlab=expression(pi),ylab=expression(L(pi)),main = "L",pch=16,type='b')
segments(sn/n,0,sn/n,(sn/n)^sn*(1-sn/n)^(n-sn),lty=2)
axis(1,pp)
axis(2,las=2)
Lp[is.infinite(Lp[,2]),2]<- - 100
plot(pp,Lp[,3],axes=F,xlab=expression(pi),ylab=expression(L(pi)),main = "log L",pch=16,type='b',ylim=c(-8,-3))
segments(sn/n,-9,sn/n,log((sn/n)^sn*(1-sn/n)^(n-sn)),lty=2)
axis(1,pp)
axis(2,las=2)

fig.def(6)
```


### Abbiamo trovato il vero $\pi$?

Ovviamente $\hat\pi$ non è $\pi$ che non conosceremo mai, $\hat\pi=0.6$ è il valore _più verosimile_ tra tutti i possibili valori di $\pi$, ma non è $\pi$.
Ci possiamo chiedere se, per esempio, l'ipotesi $\pi=0.5$ è _"impossibile"_.
Anche in questo caso la risposta è negativa, $\pi=0.5$ è solo, alla luce dei dati, _meno verosimile_ dell'ipotesi $\pi=0.6$. E possiamo anche calcolare di di quanto:
\[\frac{L(\hat\pi=0.6)}{L(\pi=0.5)}=\frac{`r dbinom(3,5,.6)`}{`r dbinom(3,5,.5)`}=`r dbinom(3,5,.6)/dbinom(3,5,.5)`\]

Alla luce dei dati (3 successi su 5 estrazioni) il valore $\hat\pi=0.6$ è il $`r (dbinom(3,5,.6)/dbinom(3,5,.5)-1)*100`\%$ _più verosimile_ di $\pi=0.5$.
\[
  (`r dbinom(3,5,.6)/dbinom(3,5,.5)`-1)\times 100 \%= `r (dbinom(3,5,.6)/dbinom(3,5,.5)-1)*100`\%
\]


### Muoviamo anche $S_n$


```{r , results='asis', echo=FALSE, out.extra=''}
if (!html)  par(mfrow=c(3,2),cex=cex)

  n <- 5
  for (sn in 0:5){
  pp <- (0:10)/10
  Lp <- data.frame(pp^sn*(1-pp)^(n-sn))
  rnm <-paste("$\\pi=",pp,"$", sep = "")
  rownames(Lp) <- rnm
  names(Lp) <- "$L(\\pi)$   "
  plot(pp,Lp[,1],axes=F,xlab=expression(pi),ylab=expression(L(pi)))
  segments(sn/n,0,sn/n,(sn/n)^sn*(1-sn/n)^(n-sn),lty=2)
  axis(1,pp)
  axis(2,las=2)
  
  title(bquote(s[5]==.(sn)))
 
}
```

In sintesi, lo spazio $X\times\Theta$ è l'incrocio tra tutti i possibili $\pi$ e tutti i possibili $s_n$, ne esce una matrice con 10 righe e 10 colonne dove le righe rappresentano $s_n$ e le colonne $\pi$.

```{r 12-Verosimiglianza-10}
pig <- (0:10)/10
sn  <- (0:5)
LX  <- outer(pig,sn,function(p,x)dbinom(x,5,p))
dimnames(LX)[[1]] <- paste("$\\pi=",pig,"$",sep="")
dimnames(LX)[[2]] <- paste("$s_{5}=",sn,"$",sep="")

kable(LX,row.names = T,booktabs = T, escape = F,linesep = "", digits = 4)
```

questa tabella, letta per righe ci indica la probabilità, letta per colonne ci indica la _verosimiglianza_.

## La Funzione di Verosimiglianza 

:::: {.info data-latex=""}
::: {.definition name="Funzione di Verosimiglianza"}
Siano $x_1,...,x_n$ $n$ osservazioni di $X\sim \mathscr{L}(\theta)$, $\theta\in\Theta$, si definisce la verosimiglianza $L$ di $\theta$ la funzione:
\[L(\theta;x_1,...,x_n)=L(\theta)\propto P(X_1=x_1,...,X_n=x_n;\theta)\]
:::
::::

La funzione di verosimiglianza è una funzione in $\theta$ (la variabile) per 
$x_1,...,x_n$ fissi. Indica quanto un particolare valore di $\theta$ è supportato dai dati.
Più alta è la verosimiglianza più i valori di $\theta$ che la rendono alta sono supportati dall'evidenza campionaria.
Se $x_1,..,x_n$ sono osservazioni $IID$ otteniamo
\begin{eqnarray*}
L(\theta) &\propto& P(X_1=x_1;\theta)\cdot...\cdot P(X_n=x_n;\theta) \\
          &\propto& f(x_1;\theta)\cdot...\cdot f(x_n;\theta)\\
          &\propto& \prod_{i=1}^n f(x_i;\theta)
\end{eqnarray*}

:::: {.info data-latex=""}
::: {.definition name="Log Verosimiglianza"}
Si definisce la log-verosimiglianza $\ell$:
\begin{eqnarray*}
\ell(\theta) &=& \log L(\theta) \\
             &=& \log \prod_{i=1}^n f(x_i;\theta)\\
             &=& \sum_{i=1}^n \log f(x_i;\theta)
\end{eqnarray*}
:::
::::

## La Stimatore di massima Verosimiglianza 


:::: {.info data-latex=""}
::: {.definition name="Stimatore du Massima Verosimiglianza"}
Lo stimatore di *massima verosimiglianza* per $\theta$ è
\begin{eqnarray*}
\hat\theta &=& \operatorname*{\text{argmax}}_{\theta\in\Theta} L(\theta)\\
           &=& \operatorname*{\text{argmax}}_{\theta\in\Theta} \ell(\theta)
\end{eqnarray*}

\[\hat\theta:L(\hat\theta)>L(\theta), \forall\theta\neq\hat\theta, \qquad\ell(\hat\theta)>\ell(\theta), \forall\theta\neq\hat\theta\]
:::
::::

## Il Principio di Verosimiglianza

Secondo la teoria della verosimiglianza, dato un modello statistico 
tutta l'informazione che un campione 
$\mathbf{x}=(x_1,...,x_n)$ porge a $\theta$ è contenuta nella sua funzione di
verosimiglianza.

## Verosimiglianza e Statistiche Sufficienti

da scrivere

## Caso Bernoulli urna infinita.

Se l'urna è infinita $N\to\infty$, allora $\pi\in[0,1]$. 
Le variabili $X_1,...,X_n$ tutte replicazioni IID di $X\sim \text{Ber}(\pi)$, si realizzano in $x_1,...,x_n$.

__Esempio.__ $n=5$, $x_1=0,x_2=1,x_3=1,x_4=0,x_5=1$, 
La probabilità della singola estrazione è
\[P(X_i=x_i;\pi)=f(x_i;\pi)=\pi^{x_i}(1-\pi)^{1-x_i}\]

La verosimiglianza è
\begin{eqnarray*}
L(\pi)     &\propto& \prod_{i=1}^n f(x_i;\pi)\\
           &=& \prod_{i=1}^n \pi^{x_i}(1-\pi)^{1-x_i}\\
           &=& \pi^{x_1}(1-\pi)^{1-x_1} \pi^{x_2}(1-\pi)^{1-x_2} ... \pi^{x_n}(1-\pi)^{1-x_n}\\
           &=& \pi^{x_1}\pi^{x_2}...\pi^{x_n}\quad (1-\pi)^{1-x_1}(1-\pi)^{1-x_2}...(1-\pi)^{1-x_n}\\
           &=& \pi^{x_1+x_2+...+x_n}(1-\pi)^{1-x_1+1-x_2+...+1-x_n}\\
           &=& \pi^{\sum_{i=1}^n x_i}(1-\pi)^{n-\sum_{i=1}^n x_i}\\
           &=& \pi^{s_n}(1-\pi)^{n-s_n}, \qquad s_n=\sum_{i=1}^n x_i
\end{eqnarray*}

La statistica $s_n$ contiene **tutta** l'informazione del campione $x_1,...,x_n$.
La log-verosimiglianza è
\begin{eqnarray*}
\ell(\pi)  &=& \log L(\pi)\\
           &=& \log \pi^{s_n}(1-\pi)^{n-s_n}\\
           &=& \log \pi^{s_n} + \log (1-\pi)^{n-s_n}\\
           &=& s_n \log \pi + (n-s_n) \log (1-\pi)
\end{eqnarray*}

Per derivare il $\pi$ che rende massima la verosimiglianza si deve derivare la funzione $\ell$ ed uguagliare a zero la derivata prima:
\[\ell'(\pi)= \frac{s_n}{\pi}+(-1)\frac{n-s_n}{1-\pi}=\frac{s_n}{\pi}-\frac{n-s_n}{1-\pi}\]

$\hat\pi$ è dunque quel valore tale che
\[\ell'(\hat\pi)=0\]

Eguagliamo a zero la derivata prima della log verosimiglianza:
\begin{eqnarray*}
\ell'(\pi)  &=& 0 \\
\frac{s_n}{\pi}-\frac{n-s_n}{1-\pi}          &=& 0 \\
\frac{s_n(1-\pi)-(n-s_n)\pi}{\pi(1-\pi)}     &=& 0\qquad \text{il denominatore è ininfluente} \\
s_n - s_n \pi - n \pi + s_n \pi              &=& 0 \\
s_n- n \pi                                   &=& 0\\
n\pi                                         &=& s_n \\
\hat\pi                                      &=& \frac{s_n}n\\
                                             &=& \frac{\sum_{i=1}^n x_i}n
\end{eqnarray*}

Se $n=5$, $s_5=3$ allora:
\[\hat\pi=\frac{3}{5}=0.6\]

$L(\pi;s_5=3)$, $\ell(\pi;s_5=3)$.

```{r 12-Verosimiglianza-11}
fig.def()
```

```{r 12-Verosimiglianza-12}
sn <- 3; n<-5
par(mfrow=c(1,2),cex=cex)
curve(x^3*(1-x)^2,0,1,axes=F,xlab=expression(pi),ylab=expression(L(pi)))
axis(1,pp)
axis(2,las=2)
segments(sn/n,0,sn/n,(sn/n)^sn*(1-sn/n)^(n-sn),lty=2)

curve(log(x^3*(1-x)^2),0,1,axes=F,xlab=expression(pi),ylab=expression(log~L(pi)))
axis(1,pp)
axis(2,las=2)
segments(sn/n,-15,sn/n,log((sn/n)^sn*(1-sn/n)^(n-sn)),lty=2)
par(cex=cex)

```

### Calcolo delle proprietà di $\hat\pi$

Dunque

:::: {.info data-latex=""}
Siano $X_1,...X_n$ $n$ VC IID, tali che $X_i\sim\text{Ber}(\pi)$ lo stimatore
di massima verosimiglianza per $\pi$ è
\[\hat \pi=\frac 1n \sum_{i=1}^nX_i\]
::::

Il _vero_ valore di $\pi$ è incognito ma sappiamo che:

:::: {.info data-latex=""}
$\hat\pi$ è corretto per $\pi$, infatti
\[E(\hat\pi)=E\left(\frac{1}n\sum_{i=1}^n X_i\right)=\frac{1}n\sum_{i=1}^nE(X_i)=\frac{\pi+...+\pi}{n}=\frac n n\pi=\pi\]

E quindi
\[MSE(\hat\pi)=V(\hat\pi)=\frac{\pi(1-\pi)}{n}\]
che è ancora funzione di $\pi$.
::::

:::: {.info data-latex=""}
Lo stimatore $\hat\pi$ per $\pi$ è _consistente_, infatti
\[\lim_{n\to +\infty}MSE(\hat\pi)=\lim_{n\to +\infty}\frac{\pi(1-\pi)}{n}=0\]

$\hat\pi$ è _corretto_ e _consistente_ per $\pi$.
::::

Osserviamo che:

:::: {.info data-latex=""}
\[SE(\hat\pi)=\sqrt{\frac{\pi(1-\pi)}{n}}\]
::::

È un risultato teorico che dipende dal _vero_ $\pi$, che non conosciamo.

:::: {.info data-latex=""}
L'errore di stima si stima sostituendo a $\pi$ la sua stima $\hat\pi$
\[\widehat{SE(\hat\pi)}=\sqrt{\frac{\hat\pi(1-\hat\pi)}{n}}\]
::::

Se $\hat\pi=0.6$ e $n=5$
\[\widehat{SE(\hat\pi)}=\sqrt{\frac{0.6(1-0.6)}{5}}=`r sqrt(.6*(1-.6)/5)`\]

:::: {.nota data-latex=""}
Lo Standard Error è l'ordine di grandezza dell'errore commesso.
::::

### Se $n$ aumenta e $\hat\pi=0.6$

Se $n=10$ e $s_{10}=6$, allora anche in questo caso
\[\hat\pi=\frac 6{10}=0.6\]

ma
\[\widehat{SE(\hat\pi)}=\sqrt{\frac{0.6(1-0.6)}{10}}=`r sqrt(.6*(1-.6)/10)`.\]

Se $n=20$ e $s_{10}=12$, allora anche in questo caso
\[\hat\pi=\frac {12}{20}=0.6\]

e
\[\widehat{SE(\hat\pi)}=\sqrt{\frac{0.6(1-0.6)}{20}}=`r sqrt(.6*(1-.6)/20)`.\]

Se $n=100$ e $s_{100}=60$, allora anche in questo caso
\[\hat\pi=\frac {60}{100}=0.6\]

e
\[\widehat{SE(\hat\pi)}=\sqrt{\frac{0.6(1-0.6)}{100}}=`r sqrt(.6*(1-.6)/100)`.\]

Se $n=1000$ e $s_{10}=600$, allora anche in questo caso
\[\hat\pi=\frac {600}{1~000}=0.6\]

e
\[\widehat{SE(\hat\pi)}=\sqrt{\frac{0.6(1-0.6)}{1000}}=`r sqrt(.6*(1-.6)/1000)`.\]


Osserviamo nel grafico $L(\pi;s_n=0.6\cdot n)$ e $\ell(\pi;s_n=0.6\cdot n)$ per $n=5,10,20,100,1~000$

```{r 12-Verosimiglianza-13}
sn<-3; n <- 5
L <- function(x) x^(sn)*(1-x)^(n-sn)
l <- function(x) log(L(x))
par(mfrow=c(1,2),cex=cex)
curve(L(x)/L(sn/n),0,1,axes=F,xlab=expression(pi),ylab=expression(L(pi)))

sn <-6; n <- 10
curve(L(x)/L(sn/n),add=T,col=ared)

sn <-12; n <- 20
curve(L(x)/L(sn/n),add=T,col=3)

sn <-60; n <- 100
curve(L(x)/L(sn/n),add=T,n=1001,col=4)

axis(1,pp)
axis(2,las=2)

sn <-600; n <- 1000
curve(L(x)/L(sn/n),add=T,n=1001,col=5)

axis(1,pp)
axis(2,las=2)
segments(sn/n,0,sn/n,1,lty=2)

sn<-3; n <- 5

curve(l(x)-l(.6),0,1,axes=F,xlab=expression(pi),ylab=expression(log~L(pi)))

sn <-6; n <- 10
curve(l(x)-l(.6),add=T,col=ared)

sn <-12; n <- 20
curve(l(x)-l(.6),add=T,col=3)

sn <-60; n <- 100
curve(l(x)-l(.6),add=T,col=4)

axis(1,pp)
axis(2,las=2)
segments(sn/n,-10,sn/n,0,lty=2)

sn <-600; n <- 1000
curve(l(x)-l(.6),add=T,col=5)

axis(1,pp)
axis(2,las=2)
segments(sn/n,-10,sn/n,0,lty=2)

par(cex=cex)

```

### L'ipotesi $\pi=0.5$

```{r 12-Verosimiglianza-14}
n  <- 5
sn <- .6*n
```

Se $n=`r n`$, $s_n=`r sn`$ il valore $\hat\pi=0.6$ è il $`r (dbinom(sn,n,.6)/dbinom(sn,n,.5)-1)*100`\%$ _più verosimile_ di $\pi=0.5$.
\[\frac{L(0.6;s_5=3)}{L(0.5;s_5=3)}=\frac{0.6^{`r sn`}(1-0.6)^{`r n-sn`}}{0.5^{`r sn`}(1-0.5)^{`r n-sn`}}=`r dbinom(sn,n,.6)/dbinom(sn,n,.5)`\]

```{r 12-Verosimiglianza-15}
n  <- 10
sn <- .6*n
```

Se $n=`r n`$, $s_n=`r sn`$ il valore $\hat\pi=0.6$ è il $`r (dbinom(sn,n,.6)/dbinom(sn,n,.5)-1)*100`\%$ _più verosimile_ di $\pi=0.5$.
\[\frac{L(0.6;s_5=3)}{L(0.5;s_5=3)}=\frac{0.6^{`r sn`}(1-0.6)^{`r n-sn`}}{0.5^{`r sn`}(1-0.5)^{`r n-sn`}}=`r dbinom(sn,n,.6)/dbinom(sn,n,.5)`\]

```{r 12-Verosimiglianza-16}
n  <- 20
sn <- .6*n
```

Se $n=`r n`$, $s_n=`r sn`$ il valore $\hat\pi=0.6$ è il $`r (dbinom(sn,n,.6)/dbinom(sn,n,.5)-1)*100`\%$ _più verosimile_ di $\pi=0.5$.
\[\frac{L(0.6;s_5=3)}{L(0.5;s_5=3)}=\frac{0.6^{`r sn`}(1-0.6)^{`r n-sn`}}{0.5^{`r sn`}(1-0.5)^{`r n-sn`}}=`r dbinom(sn,n,.6)/dbinom(sn,n,.5)`\]

```{r 12-Verosimiglianza-17}
n  <- 100
sn <- .6*n
```

Se $n=`r n`$, $s_n=`r sn`$ il valore $\hat\pi=0.6$ è il $`r (dbinom(sn,n,.6)/dbinom(sn,n,.5)-1)*100`\%$ _più verosimile_ di $\pi=0.5$.
\[\frac{L(0.6;s_5=3)}{L(0.5;s_5=3)}=\frac{0.6^{`r sn`}(1-0.6)^{`r n-sn`}}{0.5^{`r sn`}(1-0.5)^{`r n-sn`}}=`r dbinom(sn,n,.6)/dbinom(sn,n,.5)`\]

```{r 12-Verosimiglianza-18}
n  <- 1000
sn <- .6*n
```

Se $n=`r n`$, $s_n=`r sn`$ il valore $\hat\pi=0.6$ è il $`r (dbinom(sn,n,.6)/dbinom(sn,n,.5)-1)*100`\%$ _più verosimile_ di $\pi=0.5$.
\[\frac{L(0.6;s_5=3)}{L(0.5;s_5=3)}=\frac{0.6^{`r sn`}(1-0.6)^{`r n-sn`}}{0.5^{`r sn`}(1-0.5)^{`r n-sn`}}=`r dbinom(sn,n,.6)/dbinom(sn,n,.5)`\]

## Il modello Poisson

Siano $X_1,...,X_n$ $n$ VC IID, replicazioni della stessa $X\sim\text{Pois}(\lambda)$, e dunque con funzione di probabilità:
\[f(x_i;\lambda)=\frac{\lambda^{x_i}}{x_i!}e^{-\lambda}\]

La verosimiglianza per $\lambda$ è
\begin{eqnarray*}
  L(\lambda) &=& \prod_{i=1}^n\frac{\lambda^{x_i}}{x_i!}e^{-\lambda}\\
             &=& \frac{\lambda^{x_1}}{x_1!}e^{-\lambda}\cdot \frac{\lambda^{x_2}}{x_2!}e^{-\lambda}\cdot ...\cdot \frac{\lambda^{x_n}}{x_n!}e^{-\lambda}\\
             &=& \frac{1}{x_1!x_2!...x_n!} ~ \lambda^{x_1}\lambda^{x_2}...\lambda^{x_n} ~ e^{-\lambda}e^{-\lambda}...e^{-\lambda}\\
             &=& \frac{1}{\prod_{i=1}^n x_i!} \lambda^{x_1+...+x_n} e^{-\lambda-...-\lambda}\\
             &\propto& \lambda^{\sum_{i=1}^n x_i} e^{-n\lambda}\\
             &\propto& \lambda^{s_n} e^{-n\lambda},\qquad s_n=\sum_{i=1}^n x_i
\end{eqnarray*}

Tutta l'**informazione** sulla Poisson è contenuta nella statistica $s_n$.


### La log-verosimiglianza della Poisson

Essendo
\[L(\lambda)\propto \lambda^{s_n} e^{-n\lambda}\]

Allora
\begin{eqnarray*}
          \ell(\lambda)   &=& \log \lambda^{s_n} e^{-n\lambda} \\
                          &=& \log \lambda^{s_n} + \log e^{-n\lambda} \\
                          &=& s_n\log\lambda - n\lambda,\qquad \text{in quanto } \log e^a = a
\end{eqnarray*}

### La stima di massima verosimiglianza della Poisson

Essendo
\[\ell(\lambda)=s_n\log\lambda - n\lambda\]

Allora
\[
          \ell'(\lambda) = \frac {s_n}\lambda-n
\]

E dunque
\begin{eqnarray*}
  \ell'(\lambda)            &=& 0\\
  \frac {s_n}\lambda-n      &=& 0\\
  \frac {s_n}\lambda        &=& n\\
  n\lambda                  &=& s_n\\
  \hat\lambda               &=& \frac{s_n}n\\
  \hat\lambda               &=& \frac{1}n\sum_{i=1}^n x_i
\end{eqnarray*}

### Proprietà dello stimatore di massima verosimiglianza della Poisson $\hat\lambda$

Dunque

:::: {.info data-latex=""}
Siano $X_1,...X_n$ $n$ VC IID, tali che $X_i\sim\text{Pois}(\lambda)$ lo stimatore
di massima verosimiglianza per $\pi$ è
\[\hat \lambda=\frac 1n \sum_{i=1}^nX_i\]
::::

:::: {.info data-latex=""}
Correttezza:
\[
  E(\hat\lambda) =  E\left(\frac{1}n\sum_{i=1}^n X_i\right) = \frac 1 n \sum_{i=1}^n E(X_i) = \frac 1 n \sum_{i=1}^n \lambda = \lambda
\]
::::

:::: {.info data-latex=""}
Mean Squared Error:
\[
  MSE(\hat\lambda) = V(\hat\lambda)
                   = V\left(\frac 1 n \sum_{i=1}^n X_i\right)
                 = \frac 1 {n^2} \sum_{i=1}^n V(X_i)
                 = \frac n {n^2} \lambda
                 = \frac {\lambda}n
\]
::::

:::: {.info data-latex=""}
Consistenza:
\[
  \lim_{n\to+\infty} MSE(\hat\lambda) = \lim_{n\to+\infty} \frac {\lambda}n = 0
\]
::::

:::: {.info data-latex=""}
Standard Error
\[SE(\hat\lambda)=\sqrt{\frac {\lambda}n}\]

Standard Error stimato
\[\widehat{SE(\hat\lambda)}=\sqrt{\frac {\hat\lambda}n}\]
::::

### Esempio $n=5$

```{r 12-Verosimiglianza-19}
set.seed(1)
n <- 5
xpois <- rpois(5,4.6)
```
Il numero di clienti del negozio $A$ è distribuito come una Poisson di parametro $\lambda$ incognito. Dopo $n=`r n`$ giorni di osservazione si sono osservati i seguenti ingressi $(`r xpois`)$.
La stima $\hat\lambda$ di  $\lambda$ è
\[\hat\lambda=\frac 1 5`r sum(xpois)`=`r mean(xpois) `\]

Lo Standard Error stimato
\[\widehat{SE(\hat\lambda)}=\sqrt{\frac {`r mean(xpois) `}`r n`}=`r sqrt(mean(xpois)/n)`\]


```{r 12-Verosimiglianza-20}
par(cex=cex)
par(mfrow=c(1,2),cex=cex)
sn <- sum(xpois)
n <- 5
se <- sqrt(sn/n/n)
L <- function(x) x^sn*exp(-n*x)/prod(factorial(xpois))*10000
curve(L,0,12,axes=F,xlab=expression(lambda),ylab = expression(L(lambda)))
axis(1,c(seq(0,10,by=2),sn/n))
axis(2,las=2)
segments(sn/n,0,sn/n,L(sn/n),lty=2)

l <- function(x) log(x^sn*exp(-n*x)/prod(factorial(xpois))*10000)
curve(l,0,10,axes=F,xlab=expression(lambda),ylab = expression(log~L(lambda)))
axis(1,c(seq(0,12,by=2),sn/n))
axis(2,las=2)
segments(sn/n,-100,sn/n,l(sn/n),lty=2)
par(cex=cex)
```

### Esempio $n=50$

```{r 12-Verosimiglianza-21}
set.seed(1)
n <- 50
hl <- mean(xpois)
```
Il numero di clienti del negozio $A$ è distribuito come una Poisson di parametro $\lambda$ incognito. Dopo $n=`r n`$ giorni di osservazione si è osservata una media di ingressi pari a ingressi $(`r hl`)$.
La stima $\hat\lambda$ di  $\lambda$ è
\[\hat\lambda=`r hl`\]

Lo Standard Error stimato
\[\widehat{SE(\hat\lambda)}=\sqrt{\frac {`r mean(xpois) `} {`r n`}}=`r sqrt(mean(xpois)/n)`\]


```{r 12-Verosimiglianza-22}
par(cex=cex)
par(mfrow=c(1,2),cex=cex)
n <- 50
sn <- mean(xpois)*n


se <- sqrt(hl/n)
L <- function(x) x^sn*exp(-n*x)/3.5e52
curve(L,max(0,sn/n-4*se),sn/n+5*se,axes=F,xlab=expression(lambda),ylab = expression(L(lambda)))
axis(1,c(seq(0,sn/n+5*se,by=.2),sn/n))
axis(2,las=2)
segments(sn/n,0,sn/n,L(sn/n),lty=2)
l <- function(x) log(x^sn*exp(-n*x)/3.5e52)
curve(l,max(0,sn/n-4*se),sn/n+5*se,axes=F,xlab=expression(lambda),ylab = expression(log~L(lambda)))
axis(1,c(seq(0,sn/n+5*se,by=.2),sn/n))
axis(2,las=2)
segments(sn/n,-100,sn/n,l(sn/n),lty=2)
```



## Il modello Normale

Siano $X_1,...,X_n$ $n$ VC IID, replicazioni della stessa $X\sim N(\mu,\sigma^2)$, e dunque con funzione di probabilità:
\[f(x_i;\mu,\sigma^2)\]

:::: {.info data-latex=""}
La verosimiglianza per $(\mu,\sigma^2)$ è
\begin{eqnarray*}
  L(\lambda) &=& \prod_{i=1}^n f(x_i;\mu,\sigma^2)
\end{eqnarray*}
::::

La log-verosimiglianza della Normale

Allora
\begin{eqnarray*}
          \ell(\mu,\sigma^2)   &=& \log \prod_{i=1}^n f(x_i;\mu,\sigma^2)\\
                               &=& \sum_{i=1}^n \log  f(x_i;\mu,\sigma^2)
\end{eqnarray*}


### Verosimiglianza e log-verosimiglianza della Normale


```{r 12-Verosimiglianza-23}
fig.def(5)
```


```{r 12-Verosimiglianza-24}
par(cex=cex)
set.seed(2)
n <- 10
xnorm <- rnorm(n,1)
mmu <- seq(1-4/sqrt(n),1+5/sqrt(n),length.out = 101)
ss2 <- seq(0,sqrt(n),length.out = 101)
Lms <- Vectorize(function(x,y) prod(dnorm(xnorm,x,y)))
LL <- outer(mmu,ss2,Lms)
LL <- LL/max(LL)

muh <- mean(xnorm)
sh2 <- mean(xnorm^2)-muh^2
sh  <- sqrt(sh2)
s2  <- (n)/(n-1)*sh2
se  <- sh/sqrt(n-1)


ms <- expand.grid(mmu,ss2)
ll <- Lms(ms[,1],ms[,2])
mshat <- ms[which(ll==max(ll)),]
#mshat <- c(muh,sqrt(sh2))
Lmax   <- Lms(mshat[1],mshat[2])

xxx<-mmu
yyy<-ss2

par(mfrow=c(1,2),cex=cex)
M <- persp(mmu,ss2,LL,box=F,xlab=expression(mu),ylab=expression(sigma^2),theta = 50,expand = .6,border = NA,shade = .5,ltheta = +30,r=.01)

arrows(
  trans3d(0,min(yyy)-.1,0,M)$x,
  trans3d(0,min(yyy)-.1,0,M)$y,
  trans3d(0,max(yyy)+.1,0,M)$x,
  trans3d(0,max(yyy)+.1,0,M)$y,length = .1)

arrows(
  trans3d(min(xxx)-.1,0,0,M)$x,
  trans3d(min(xxx)-.1,0,0,M)$y,
  trans3d(max(xxx)+.1,0,0,M)$x,
  trans3d(max(xxx)+.1,0,0,M)$y,length = .1)

arrows(
  trans3d(0,0,-.05,M)$x,
  trans3d(0,0,-.05,M)$y,
  trans3d(0,0,.5,M)$x,
  trans3d(0,0,1.1,M)$y,length = .1)


mx <- mshat[,1]
my <- mshat[,2]
points(rbind(
  trans3d(mx,max(yyy)+.1,0,M),
  trans3d(mx,min(yyy)-.1,0,M)
  ), type = "l",lty=2)

points(rbind(
  trans3d(max(xxx)+.1,my,0,M),
  trans3d(min(xxx)-.1,my,0,M)
  ), type = "l",lty=2)


points(rbind(
  trans3d(mx,my,0,M),
  trans3d(mx,my,max(LL),M)
  ), type = "l",lty=2)


text(trans3d(max(xxx),0,+.05,M),expression(mu))
text(trans3d(mx,0,-.05,M),expression(hat(mu)))


text(trans3d(0,max(yyy)+.5,-.05,M),expression(sigma^2))
text(trans3d(0,my,+.05,M),expression(hat(sigma^2)))

text(trans3d(+1.5,.1,1.1,M),expression(L(mu,sigma^2)))


Lms <- Vectorize(function(x,y) sum(dnorm(xnorm,x,y,log = T)))
LL <- outer(mmu,ss2,Lms)
#LL <- LL/max(LL)
LL[is.infinite(LL)]<- NA
LL <- LL-max(LL,na.rm = T)



ms <- expand.grid(mmu,ss2)
ll <- Lms(ms[,1],ms[,2])
mshat <- ms[which(ll==max(ll)),]
#mshat <- c(muh,sqrt(sh2))
Lmax   <- Lms(mshat[1],mshat[2])

xxx<-mmu
yyy<-ss2

M <- persp(mmu,ss2,LL+2,box=F,xlab=expression(mu),ylab=expression(sigma^2),theta = 50,expand = .6,border = NA,shade = .5,ltheta = +30,zlim = c(-.5,3),r=.01)

arrows(
  trans3d(0,min(yyy)-.1,0,M)$x,
  trans3d(0,min(yyy)-.1,0,M)$y,
  trans3d(0,max(yyy)+.1,0,M)$x,
  trans3d(0,max(yyy)+.1,0,M)$y,length = .1)

arrows(
  trans3d(min(xxx)-.1,0,0,M)$x,
  trans3d(min(xxx)-.1,0,0,M)$y,
  trans3d(max(xxx)+.1,0,0,M)$x,
  trans3d(max(xxx)+.1,0,0,M)$y,length = .1)

arrows(
  trans3d(0,0,-1,M)$x,
  trans3d(0,0,-1,M)$y,
  trans3d(0,0,2.9,M)$x,
  trans3d(0,0,2.9,M)$y,length = .1)


mx <- mshat[,1]
my <- mshat[,2]
points(rbind(
  trans3d(mx,max(yyy)+.1,0,M),
  trans3d(mx,min(yyy)-.1,0,M)
  ), type = "l",lty=2)

points(rbind(
  trans3d(max(xxx)+.1,my,0,M),
  trans3d(min(xxx)-.1,my,0,M)
  ), type = "l",lty=2)


points(rbind(
  trans3d(mx,my,0,M),
  trans3d(mx,my,max(LL,na.rm = T),M)
  ), type = "l",lty=2)


text(trans3d(max(xxx),0,.5,M),expression(mu))
text(trans3d(mx,0,-.5,M),expression(hat(mu)))


text(trans3d(0,max(yyy),1,M),expression(sigma^2))
text(trans3d(0,my,1,M),expression(hat(sigma^2)))

text(trans3d(0,.5,3,M),expression(log~L(mu,sigma^2)))


```

### Le stime di massima verosimiglianza della Normale

Per ottenere $\hat\mu$ e $\hat\sigma^2$ bisogna eguagliare a zero il sistema di 
equazioni di derivate di $\ell(\mu,\sigma^2)$ rispetto a $\mu$ e $\sigma^2$
\[
\begin{cases}
  \frac{d\ell(\mu,\sigma^2)}{d\mu}=0\\
  \frac{d\ell(\mu,\sigma^2)}{d\sigma^2}=0
\end{cases}
\]

:::: {.info data-latex=""}
::: {.proposition}
\begin{eqnarray*}
  \hat\mu            &=& \frac 1 n \sum_{i=1}^n x_i\\
  \hat\sigma^2       &=& \frac 1 n \sum_{i=1}^n(x_i-\hat\mu)^2\\
                     &=& \frac 1 n \sum_{i=1}^n x_i^2 -\hat\mu^2
\end{eqnarray*}
:::
::::

Tutta l'**informazione** del campione è contenuta nelle statistiche $\sum_{i=1}^n x_i$ 
e $\sum_{i=1}^n x_i^2$.

::: {.proof}
\begin{eqnarray*}
  L(\mu,\sigma^2;\,\mathbf{x}) &=&  \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}}e^
  {-\frac 12\left(\frac{(x_i-\mu)^2}{\sigma^2}\right)}\\
  &=&\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)^n 
  e^{-\frac 1{2\sigma^2}((x_1-\mu)^2+(x_2-\mu)^2+...+(x_n-\mu)^2)}\\
  &\propto& \sigma^{-2n}\exp\left\{-\frac 1{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\right\}\\
\end{eqnarray*}
\begin{eqnarray*}  
  \ell(\mu,\sigma^2) &=& \log L(\mu,\sigma^2;\,\mathbf{x})\\
  &=& \log \sigma^{-2n}\exp\left\{-\frac 1{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\right\}\\
  &=& -n \log \sigma^2-\frac 1{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\\
\end{eqnarray*}
\begin{eqnarray*}  
  \frac{d\ell(\mu,\sigma^2)}{d\mu} &=& +\frac 2{2\sigma^2}\sum_{i=1}^n(x_i-\mu)\\
  \frac{d\ell(\mu,\sigma^2)}{d\sigma^2} &=& -\frac n{\sigma^2}+\frac 1{(\sigma^2)^2}\sum_{i=1}^n(x_i-\mu)^2\\
  &=& \frac{-n\sigma^2+\sum_{i=1}^n(x_i-\mu)}{(\sigma^2)^2}\\
  \frac{d\ell(\mu,\sigma^2)}{d\mu} &=& 0 \Rightarrow \hat\mu=\frac 1n \sum_{i=1}^nx_i\\
  \frac{d\ell(\mu,\sigma^2)}{d\sigma^2} &=& 0 \Rightarrow \hat\sigma^2=\frac 1 n \sum_{i=1}^n(x_i-\hat\mu)^2
\end{eqnarray*}
:::

### Proprietà di $\hat\mu$

:::: {.info data-latex=""}
Correttezza per $\mu$:
\[
  E(\hat\mu) =  E\left(\frac{1}n\sum_{i=1}^n X_i\right) = \frac 1 n \sum_{i=1}^n E(X_i) = \frac 1 n \sum_{i=1}^n \mu = \mu
\]
::::

:::: {.info data-latex=""}
Mean Squared Error per $\mu$:
\[
  MSE(\hat\mu) = V(\hat\mu)
                   = V\left(\frac 1 n \sum_{i=1}^n X_i\right)
                 = \frac 1 {n^2} \sum_{i=1}^n V(X_i)
                 = \frac n {n^2} \sigma^2
                 = \frac {\sigma^2}n
\]
::::

:::: {.info data-latex=""}
Consistenza per $\mu$:
\[
  \lim_{n\to+\infty} MSE(\hat\mu) = \lim_{n\to+\infty} \frac {\sigma^2}n = 0
\]

E lo Standard Error:
\[SE(\hat\mu)=\sqrt{\frac {\sigma^2}n}\]
::::

Standard Error stimato tra poco verrà ricavato \@ref(ssem).

### Proprietà di $\hat\sigma^2$ {#vnorm}

:::: {.info data-latex=""}
Correttezza per $\hat\sigma^2$:
\[
  E(\hat\sigma^2) =  \frac {n-1}{n}\sigma^2
\]
$\hat\sigma^2$ non è stimatore corretto per $\sigma^2$.
::::

:::: {.info data-latex=""}
Correzione di $\hat\sigma^2$
\[
  S^2=\frac{n}{n-1}\hat\sigma^2=\frac{n}{n-1}\frac{1}n\sum_{i=1}^n(X_i-\hat\mu)^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\hat\mu)^2
\]
::::

Osserviamo che
\[
  E(S^2)=E\left(\frac{n}{n-1}\hat\sigma^2\right)=\frac{n}{n-1}E\left(\hat\sigma^2\right)= \frac{n}{n-1}\frac {n-1}{n}\sigma^2=\sigma^2
\]

$S^2$ è stimatore corretto per $\sigma^2$.

### Lo $SE$ di $\hat\mu$ {#ssem}

:::: {.info data-latex=""}
Standard Error
\[SE(\hat\mu)=\sqrt{\frac {\sigma^2}n}\]

Standard Error stimato.
\[\widehat{SE(\hat\mu)}=\sqrt{\frac {S^2}n}=\sqrt{\frac {\hat\sigma^2}{n-1}}\]
::::

In quanto
\[\frac {S^2}{n}=\frac 1 nS^2=\frac 1 n \frac{n}{n-1}\hat\sigma^2=\frac{\hat\sigma^2}{n-1}\]


### Esempio $n=10$
```{r 12-Verosimiglianza-25}
xnorm<-xnorm+2
muh <- muh + 2


```
Il fatturato mensile del negozio $A$ è distribuito come una Normale di parametri $\mu$ e $\sigma^2$ incogniti. Dopo $n=`r n`$ mesi di osservazione si sono osservati i seguenti fatturati $\small (`r paste("x_{",1:n,"}=",round(xnorm,3),sep="")`)$.
La stima $\hat\mu$ di  $\mu$ è
\[\hat\mu=\frac 1 {`r n`}`r sum(xnorm)`=`r muh `\]

La varianza campionaria $\hat\sigma^2$
\[\hat\sigma^2=\frac 1 n \sum_{i=1}^n(x_i-\hat\mu)^2=\frac 1 n \sum_{i=1}^n x_i^2-\hat\mu^2=\frac{`r sum(xnorm^2)`}{`r n`}-`r muh`^2=`r sh2`\]

$S^2$ la stima corretta di $\sigma^2$
\[S^2=\frac{n}{n-1}\hat\sigma^2=\frac{`r n`}{`r n-1`}`r sh2`=`r (n)/(n-1)*(sh2)`\]

Lo $SE$ stimato di $\hat\mu$ 
\[\widehat{SE(\hat\mu)} = 
  \sqrt{\frac{`r (n)/(n-1)*(sh2)`}{`r n`}} =
  `r sqrt( (n)/(n-1)*(sh2)/n)`\]


### Esempio $n=100$

```{r 12-Verosimiglianza-26}
n <- 100
```

L'ammontare delle transazioni finanziarie compiute al minuto dal server $A$ è distribuito come una Normale di parametri $\mu$ e $\sigma^2$ incogniti. Dopo $n=`r 100`$ ore di osservazione si sono osservati $\bar x=`r muh`$, $\hat\sigma=`r sh`$ .
La stima $\hat\mu$ di  $\mu$ è
\[\hat\mu=`r muh `\]

La varianza campionaria $\hat\sigma^2$
\[\hat\sigma^2=`r sh`^2=`r sh2`\]

$S^2$ la stima corretta di $\sigma^2$
\[S^2=\frac{n}{n-1}\hat\sigma^2=\frac{`r n`}{`r n-1`}`r sh2`=`r (n)/(n-1)*(sh2)`\]

Lo $SE$ stimato di $\hat\mu$ 
\[\widehat{SE(\hat\mu)} = 
  \sqrt{\frac{`r (n)/(n-1)*(sh2)`}{`r n`}} =
  `r sqrt( (n)/(n-1)*(sh2)/n)`\]


### Perché $n-1$

Per calcolare la varianza campionaria dobbiamo prima calcolare la media dei dati.
Per calcolare la media bisogna sommare i dati, per esempio se $n=3$: 
$x_1=7$, $x_2=8$ e $x_3=11$
\[x_1+x_2+x_3 = 26\]

Ma $x_1=7$, $x_2=8$ e $x_3=11$ non sono l'unica tripla di $x$ che somma a 26, ma
$n-1=2$ valori possono essere scelti liberamente (es $x_1=5$ e $x_2=15$):
Il terzo **è vincolato**:
\[x_3=26-x_1-x_2\]

Fissata la somma il sistema _ha perso un grado di libertà_.


## Proprietà degli stimatori di massima verosimiglianza

:::: {.info data-latex=""}
::: {.proposition name="Stimatori di massima verosimgilianza"}
Siano $X_1,...,X_n$ $n$ VC IID, replicazioni di $X\sim \mathscr{L}(\theta)$ e sia $\hat\theta$ lo stimatore di massima verosimiglianza per per $\theta$, allora

1. $\hat\theta$ non è sempre stimatore corretto ma è sempre corretto asintoticamente:
\[E(\hat\theta)\xrightarrow{n\to\infty}\theta\]
  

2. $\hat\theta$ non è sempre stimatore a _massima efficienza_ ma lo è sempre asintoticamente:
\[V(\hat\theta)\xrightarrow{n\to\infty}I^{-1}(\theta)\]
dove $I(\theta)$ è l'infromazione di Fisher.   
  
3. $\hat\theta$ è asintoticamente distribuito normalmente
\[\hat\theta\operatorname*{\sim}_a N(\theta,I^{-1}(\theta))\]
  

4. Lo stimatore di massima verosimiglianza è invariante alle trasformazioni monotone invertibili $g$:
  
  \[ \text{se } \psi=g(\theta), \text{ allora } \hat\psi = g(\hat\psi)\]
:::
::::

  1. La proprietà uno riguarda la correttezza. Non sempre gli SMV sono corretti
  ma lo sono sempre asintoticamente. Esempio: lo stimatore $\hat\sigma^2$ di $\sigma^2$ non è corretto solo asintoticamente
  \[E(\hat\sigma^2)=\frac{n-1}{n}\sigma^2\xrightarrow{n\to\infty}\sigma^2\]
  2. La proprietà due riguarda l'efficienza dello stimatore: non sempre lo
  SMV è il più efficiente per piccoli campioni, ma se il campione diventa grande, lo
  SMV è lo stimatore che raggiunge la varianza minima. La varianza minima è chiamata Informazione di Fisher ed è indicata con $I^{-1}(\theta)$:
\[
  I(\theta)=-E\left(\ell''(\theta)\right)
\]
dove $\ell''(\theta)$ è la derivata seconda della log verosimiglianza calcolata in $\theta$.

  - $I(\theta)$ è la curvatura media della log verosimiglianza intorno al punto $\theta$.
  - $I^{-1}(\theta)$ è un risultato teorico ed un limite sotto al quale nessuno stimatore può scendere.
  - Se esiste lo stimatore più efficiente allora è quello di _massima verosimiglianza_.
  - Esempio: $\hat\pi$, $\hat\lambda$ e $\hat\mu$ sono stimatori a efficienza massima.

\begin{eqnarray*}
   I^{-1}(\pi) &=&  \frac{\pi(1-\pi)}{n}\\
   I^{-1}(\lambda) &=&  \frac{\lambda}{n}\\
   I^{-1}(\mu) &=&  \frac{\sigma^2}{n}
\end{eqnarray*}

  3. La proprietà tre ci garantisce che, per $n$ sufficientemente alto, sappiamo 
  la distribuzione degli SMV
  
  - Esempio: lo stimatore $\hat\pi$ di $\pi$, dal TLC
  \[\hat\pi\operatorname*{\sim}_a N\left(\pi,\frac{\pi(1-\pi)}{n}\right)\]
  - Esempio: lo stimatore $\hat\lambda$ di $\lambda$, dal TLC
  \[\hat\lambda\operatorname*{\sim}_a N\left(\lambda,\frac{\lambda}{n}\right)\]
  
  4. La proprietà 4 garantisce che trasformazioni invertibili dei parametri non 
  richiedono di ricalcolare la SMV.
  
  - Esempio: $\sigma=\sqrt{\sigma^2}$ e dunque $\hat\sigma=\sqrt{\hat\sigma^2}$

